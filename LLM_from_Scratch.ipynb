{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building an LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tiktoken\n",
      "  Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting regex>=2022.1.18 (from tiktoken)\n",
      "  Downloading regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "Requirement already satisfied: requests>=2.26.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tiktoken) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (2024.12.14)\n",
      "Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m120.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (781 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.7/781.7 kB\u001b[0m \u001b[31m120.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: regex, tiktoken\n",
      "Successfully installed regex-2024.11.6 tiktoken-0.8.0\n"
     ]
    }
   ],
   "source": [
    "! pip3 install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import urllib.request\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import importlib\n",
    "import tiktoken\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.2.1+cu121\n"
     ]
    }
   ],
   "source": [
    "print(\"PyTorch version:\", torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: GPT Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MultiHead Attentition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    \n",
    "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        assert (d_out % num_heads == 0), \\\n",
    "            \"d_out must be divisible by num_heads\"\n",
    "\n",
    "        self.d_out = d_out\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = d_out // num_heads # Reduce the projection dimension to match desired output dimension\n",
    "\n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.out_proj = nn.Linear(d_out, d_out)  # Linear layer to combine head outputs\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer(\n",
    "            \"mask\",\n",
    "            torch.triu(torch.ones(context_length, context_length),\n",
    "                       diagonal=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, num_tokens, d_in = x.shape\n",
    "\n",
    "        keys = self.W_key(x) # Shape: (b, num_tokens, d_out)\n",
    "        queries = self.W_query(x)\n",
    "        values = self.W_value(x)\n",
    "\n",
    "        # We implicitly split the matrix by adding a `num_heads` dimension\n",
    "        # Unroll last dim: (b, num_tokens, d_out) -> (b, num_tokens, num_heads, head_dim)\n",
    "        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim) \n",
    "        values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "\n",
    "        # Transpose: (b, num_tokens, num_heads, head_dim) -> (b, num_heads, num_tokens, head_dim)\n",
    "        keys = keys.transpose(1, 2)\n",
    "        queries = queries.transpose(1, 2)\n",
    "        values = values.transpose(1, 2)\n",
    "\n",
    "        # Compute scaled dot-product attention (aka self-attention) with a causal mask\n",
    "        attn_scores = queries @ keys.transpose(2, 3)  # Dot product for each head\n",
    "\n",
    "        # Original mask truncated to the number of tokens and converted to boolean\n",
    "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
    "\n",
    "        # Use the mask to fill attention scores\n",
    "        attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
    "        \n",
    "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "\n",
    "        # Shape: (b, num_tokens, num_heads, head_dim)\n",
    "        context_vec = (attn_weights @ values).transpose(1, 2) \n",
    "        \n",
    "        # Combine heads, where self.d_out = self.num_heads * self.head_dim\n",
    "        context_vec = context_vec.contiguous().view(b, num_tokens, self.d_out)\n",
    "        context_vec = self.out_proj(context_vec) # optional projection\n",
    "\n",
    "        return context_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "It splits the input into multiple heads by reshaping the projected query, key, and value tensors and then combines\n",
    "the results from these heads after computing attention.\n",
    "\n",
    "The splitting of the query, key, and value tensors, is achieved through tensor reshaping and transposing operations using PyTorch's .view and .transpose methods. \n",
    "\n",
    "The input is first transformed (via linear layers for queries, keys, and values) and then reshaped to represent multiple heads.\n",
    "\n",
    "The key operation is to split the d_out dimension into num_heads and head_dim, where head_dim = d_out / num_heads. \n",
    "\n",
    "This splitting is then achieved using the .view method: a tensor of dimensions (b, num_tokens, d_out) is reshaped to dimension (b, num_tokens, num_heads, head_dim).\n",
    "\n",
    "The tensors are then transposed to bring the num_heads dimension before the num_tokens dimension, resulting in a shape of (b, num_heads, num_tokens, head_dim).\n",
    "\n",
    "This transposition is crucial for correctly aligning the queries, keys, and values across the different heads and performing batched matrix multiplications efficiently.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPT Model Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_CONFIG_774M = {\n",
    "    \"vocab_size\": 50257,    # Vocabulary size\n",
    "    \"context_length\": 1024, # Context length\n",
    "    \"emb_dim\": 1280,        # Embedding dimension\n",
    "    \"n_heads\": 20,          # Number of attention heads\n",
    "    \"n_layers\": 36,         # Number of layers\n",
    "    \"drop_rate\": 0.1,       # Dropout rate\n",
    "    \"qkv_bias\": False       # Query-Key-Value bias\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layer Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "The layer normalization code normalizes the values of each of the two inputs such that they have a mean of 0 and a\n",
    "variance of 1.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    \n",
    "    def __init__(self, emb_dim):\n",
    "        super().__init__()\n",
    "        self.eps = 1e-5\n",
    "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
    "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(dim=-1, keepdim=True)\n",
    "        var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
    "        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
    "        return self.scale * norm_x + self.shift"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "This specific implementation of layer Normalization operates on the last dimension of the input tensor x, which represents the embedding dimension (emb_dim). \n",
    "\n",
    "The variable eps is a small constant (epsilon) added to the variance to prevent division by zero during normalization. \n",
    "\n",
    "The scale and shift are two trainable parameters (of the same dimension as the input) that the LLM automatically adjusts during training if it is determined that doing so would improve the model's performance on its training task. \n",
    "\n",
    "This allows the model to learn appropriate scaling and shifting that best suit the data it is processing.\n",
    "\n",
    "\n",
    "In our variance calculation method, we have opted for an implementation detail by setting unbiased=False. \n",
    "\n",
    "In the variance calculation, the number of inputs n is used to divide in the variance formula. \n",
    "\n",
    "This approach does not apply Bessel's correction, which typically uses n-1 instead of n in the denominator to adjust for bias in sample variance estimation. \n",
    "\n",
    "This decision results in a so-called biased estimate of the variance. \n",
    "\n",
    "For large-scale language models (LLMs), where the embedding dimension n is significantly large, the difference between using n and n-1 is practically negligible. \n",
    "\n",
    "We chose this approach to ensure compatibility with the GPT-2 model's normalization layers and because it reflects TensorFlow's default behavior, which was used to implement the original GPT2 model.\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FeedForward Neural Network Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GELU(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return 0.5 * x * (1 + torch.tanh(\n",
    "            torch.sqrt(torch.tensor(2.0 / torch.pi)) * \n",
    "            (x + 0.044715 * torch.pow(x, 3))\n",
    "        ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "ReLU is a piecewise linear function that outputs the input directly if it is positive; otherwise, it outputs zero. \n",
    "\n",
    "GELU is a smooth, nonlinear function that approximates ReLU but with a non-zero gradient for negative values.\n",
    "\n",
    "The smoothness of GELU can lead to better optimization properties during training, as it allows for more nuanced adjustments to the model's parameters. \n",
    "\n",
    "In contrast, ReLU has a sharp corner at zero, which can sometimes make optimization harder, especially in networks that are very deep or have complex architectures. \n",
    "\n",
    "Moreover, unlike RELU, which outputs zero for any negative input, GELU allows for a small, non-zero output for negative values. \n",
    "\n",
    "This characteristic means that during the training process, neurons that receive negative input can still contribute to the learning process, albeit to a lesser extent than positive inputs.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    \n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]), # Expansion\n",
    "            GELU(), # Activation\n",
    "            nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"]), # Contraction\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "The FeedForward module plays a crucial role in enhancing the model's ability to learn from and generalize the data. \n",
    "\n",
    "Although the input and output dimensions of this module are the same, it internally expands the embedding dimension\n",
    "into a higher-dimensional space through the first linear layer.\n",
    "\n",
    "This expansion is followed by a non-linear GELU activation, and then a contraction back to the original dimension with the second linear transformation. \n",
    "\n",
    "Such a design allows for the exploration of a richer representation space.\n",
    "\n",
    "Moreover, the uniformity in input and output dimensions simplifies the architecture by enabling the stacking of multiple layers without the need to adjust dimensions between them, thus making the model more scalable.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformer Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    \n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.att = MultiHeadAttention(\n",
    "            d_in=cfg[\"emb_dim\"],\n",
    "            d_out=cfg[\"emb_dim\"],\n",
    "            context_length=cfg[\"context_length\"],\n",
    "            num_heads=cfg[\"n_heads\"], \n",
    "            dropout=cfg[\"drop_rate\"],\n",
    "            qkv_bias=cfg[\"qkv_bias\"])\n",
    "        self.ff = FeedForward(cfg)\n",
    "        self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"])\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Shortcut connection for attention block\n",
    "        shortcut = x\n",
    "        x = self.norm1(x)\n",
    "        x = self.att(x)  # Shape [batch_size, num_tokens, emb_size]\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut  # Add the original input back\n",
    "\n",
    "        # Shortcut connection for feed forward block\n",
    "        shortcut = x\n",
    "        x = self.norm2(x)\n",
    "        x = self.ff(x)\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut  # Add the original input back\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "The given code defines a TransformerBlock class in PyTorch that includes a multi-head attention mechanism (MultiHeadAttention) and a feed forward network (FeedForward), both configured based on a provided configuration dictionary (cfg), such as GPT_CONFIG_774M\n",
    "\n",
    "Layer normalization (LayerNorm) is applied before each of these two components, and dropout is applied after them to regularize the model and prevent overfitting. \n",
    "This is also known as Pre-LayerNorm. \n",
    "\n",
    "Older architectures, such as the original transformer model, applied layer normalization after the self-attention and feed-forward networks instead, known as Post-LayerNorm, which often leads to worse training dynamics.\n",
    "\n",
    "The class also implements the forward pass, where each component is followed by a shortcut connection that adds the input of the block to its output. This critical feature helps gradients flow through the network during training and improves the learning of deep models. \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPT Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
    "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
    "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
    "        \n",
    "        self.trf_blocks = nn.Sequential(\n",
    "            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
    "        \n",
    "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.out_head = nn.Linear(\n",
    "            cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False\n",
    "        )\n",
    "\n",
    "    def forward(self, in_idx):\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
    "        x = tok_embeds + pos_embeds  # Shape [batch_size, num_tokens, emb_size]\n",
    "        x = self.drop_emb(x)\n",
    "        x = self.trf_blocks(x)\n",
    "        x = self.final_norm(x)\n",
    "        logits = self.out_head(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 1280)\n",
       "  (pos_emb): Embedding(1024, 1280)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (12): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (13): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (14): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (15): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (16): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (17): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (18): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (19): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (20): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (21): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (22): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (23): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (24): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (25): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (26): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (27): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (28): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (29): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (30): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (31): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (32): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (33): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (34): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (35): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=1280, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(2010027)\n",
    "model = GPTModel(GPT_CONFIG_774M)\n",
    "model.eval()  # Disable dropout during inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "The __init__ constructor of this GPTModel class initializes the token and positional embedding layers using the configurations passed in via a Python dictionary, cfg. \n",
    "\n",
    "These embedding layers are responsible for converting input token indices into dense vectors and adding positional information.\n",
    "\n",
    "Next, the __init__ method creates a sequential stack of TransformerBlock modules equal to the number of layers specified in cfg. \n",
    "\n",
    "Following the transformer blocks, a LayerNorm layer is applied, standardizing the outputs from the transformer blocks to stabilize the learning process. \n",
    "\n",
    "Finally, a linear output head without bias is defined, which projects the transformer's output into the vocabulary space of the tokenizer to generate logits for each token in the vocabulary.\n",
    "\n",
    "The forward method takes a batch of input token indices, computes their embeddings, applies the positional embeddings, passes the sequence through the transformer blocks, normalizes the final output, and then computes the logits, representing the next token's unnormalized probabilities. \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Generating Text from Output Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text_simple(model, idx, max_new_tokens, context_size):\n",
    "    # idx is (batch, n_tokens) array of indices in the current context\n",
    "    \n",
    "    for _ in range(max_new_tokens):\n",
    "        \n",
    "        # Crop current context if it exceeds the supported context size\n",
    "        # E.g., if LLM supports only 5 tokens, and the context size is 10 then only the last 5 tokens are used as context\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        \n",
    "        # Get the predictions\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond) ### batch, n_tokens, vocab_size\n",
    "        \n",
    "        # Focus only on the last time step\n",
    "        # (batch, n_tokens, vocab_size) becomes (batch, vocab_size)\n",
    "        logits = logits[:, -1, :]  \n",
    "\n",
    "        # Apply softmax to get probabilities\n",
    "        probas = torch.softmax(logits, dim=-1)  # (batch, vocab_size)\n",
    "\n",
    "        # Get the idx of the vocab entry with the highest probability value\n",
    "        idx_next = torch.argmax(probas, dim=-1, keepdim=True)  # (batch, 1)\n",
    "\n",
    "        # Append sampled index to the running sequence\n",
    "        idx = torch.cat((idx, idx_next), dim=1)  # (batch, n_tokens+1)\n",
    "\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "The generate_text_simple function, we use a softmax function to convert the logits into a probability distribution from which we identify the position with the highest value via torch.argmax. \n",
    "\n",
    "The softmax function is monotonic, meaning it preserves the order of its inputs when transformed into outputs. \n",
    "\n",
    "So, in practice, the softmax step is redundant since the position with the highest score in the softmax output tensor is the same position in the logit tensor. \n",
    "\n",
    "In other words, the torch.argmax function could be applied to the logits tensor directly and get identical results. \n",
    "\n",
    "However, the conversion is coded to illustrate the full process of transforming logits to probabilities, which can add additional intuition, such as that the model generates the most likely next token, which is known as greedy decoding.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0) # add batch dimension\n",
    "    return encoded_tensor\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.squeeze(0) # remove batch dimension\n",
    "    return tokenizer.decode(flat.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "Note that it's common to process millions of articles and hundreds of thousands of books -- many gigabytes of text -- when working with LLMs. However, for educational purposes, it's sufficient to work with smaller text samples like a single book to learn the main ideas and to make it possible to run it in reasonable time on consumer hardware. \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"/teamspace/studios/this_studio/J. K. Rowling - Harry Potter 1 - Sorcerer's Stone.txt\"\n",
    "url = \"/teamspace/studios/this_studio/J. K. Rowling - Harry Potter 1 - Sorcerer's Stone.txt\"\n",
    "\n",
    "if not os.path.exists(file_path):\n",
    "    with urllib.request.urlopen(url2) as response:\n",
    "        text_data = response.read().decode('utf-8')\n",
    "    with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(text_data)\n",
    "else:\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        text_data = file.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Byte Pair Encoding (BPE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "Since implementing BPE can be relatively complicated, we will use an existing Python open-source library called tiktoken. \n",
    "\n",
    "This library implements the BPE algorithm very efficiently based on source code in Rust.\n",
    "\n",
    "The algorithm underlying BPE breaks down words that aren't in its predefined vocabulary into smaller subword units or even individual characters.\n",
    "\n",
    "The enables it to handle out-ofvocabulary words. \n",
    "\n",
    "So, if the tokenizer encounters an unfamiliar word during tokenization, it can represent it as a sequence of subword tokens or characters.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Characters: 439741\n",
      "Tokens: 116724\n"
     ]
    }
   ],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "total_characters = len(text_data)\n",
    "total_tokens = len(tokenizer.encode(text_data))\n",
    "\n",
    "print(\"Characters:\", total_characters)\n",
    "print(\"Tokens:\", total_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "With 116,724 tokens, the text is very short for training an LLM.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you advertisstatesCaptanium� Keooks jumpedroleumpositive\n"
     ]
    }
   ],
   "source": [
    "start_context = \"Every effort moves you\"\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(start_context, tokenizer),\n",
    "    max_new_tokens=10,\n",
    "    context_size=GPT_CONFIG_774M[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "The model does not produce good text because it has not been trained yet.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Calculating the Training and Validation Set Losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTDatasetV1(Dataset):\n",
    "    \n",
    "    def __init__(self, txt, tokenizer, max_length, stride):\n",
    "        self.input_ids = []\n",
    "        self.target_ids = []\n",
    "\n",
    "        # Tokenize the entire text\n",
    "        token_ids = tokenizer.encode(txt, allowed_special={\"<|endoftext|>\"})\n",
    "\n",
    "        # Use a sliding window to chunk the book into overlapping sequences of max_length\n",
    "        for i in range(0, len(token_ids) - max_length, stride):\n",
    "            input_chunk = token_ids[i:i + max_length]\n",
    "            target_chunk = token_ids[i + 1: i + max_length + 1]\n",
    "            self.input_ids.append(torch.tensor(input_chunk))\n",
    "            self.target_ids.append(torch.tensor(target_chunk))\n",
    "\n",
    "    # Return the total number of rows in the dataset\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    # Return a single row from the dataset\n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.target_ids[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "The GPTDatasetV1 class is based on the PyTorch Dataset class.\n",
    "\n",
    "It defines how individual rows are fetched from the dataset. \n",
    "\n",
    "Each row consists of a number of token IDs (based on a max_length) assigned to an input_chunk tensor. \n",
    "\n",
    "The target_chunk tensor contains the corresponding targets. \n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "The following code will use the GPTDatasetV1 to load the inputs in batches via a PyTorch DataLoader:\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloader_v1(txt, batch_size=8, max_length=256, \n",
    "                         stride=128, shuffle=True, drop_last=True,\n",
    "                         num_workers=0):\n",
    "\n",
    "    # Initialize the tokenizer\n",
    "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "    # Create dataset\n",
    "    dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\n",
    "\n",
    "    # Create dataloader\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        drop_last=drop_last,    # True drops the last batch if it is shorter than the specified batch_size to prevent loss spikes during training\n",
    "        num_workers=num_workers    # The number of CPU processes to use for preprocessing\n",
    "    )\n",
    "\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "A utility function to calculate the cross-entropy loss of a given batch:\n",
    "\n",
    "In addition, a second utility function to compute the loss for a user-specified number of batches in a data loader:\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "    logits = model(input_batch)\n",
    "    loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten())\n",
    "    return loss\n",
    "\n",
    "\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        # Reduce the number of batches to match the total number of batches in the data loader\n",
    "        # if num_batches exceeds the number of batches in the data loader\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/validation ratio\n",
    "train_ratio = 0.90\n",
    "split_idx = int(train_ratio * len(text_data))\n",
    "train_data = text_data[:split_idx]\n",
    "val_data = text_data[split_idx:]\n",
    "\n",
    "\n",
    "torch.manual_seed(2010027)\n",
    "\n",
    "train_loader = create_dataloader_v1(\n",
    "    train_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_774M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_774M[\"context_length\"],\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "val_loader = create_dataloader_v1(\n",
    "    val_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_774M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_774M[\"context_length\"],\n",
    "    drop_last=False,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "\n",
    "if total_tokens * (train_ratio) < GPT_CONFIG_774M[\"context_length\"]:\n",
    "    print(\"Not enough tokens for the training loader. \"\n",
    "          \"Try to lower the `GPT_CONFIG_124M['context_length']` or \"\n",
    "          \"increase the `training_ratio`\")\n",
    "\n",
    "if total_tokens * (1-train_ratio) < GPT_CONFIG_774M[\"context_length\"]:\n",
    "    print(\"Not enough tokens for the validation loader. \"\n",
    "          \"Try to lower the `GPT_CONFIG_124M['context_length']` or \"\n",
    "          \"decrease the `training_ratio`\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### An optional check that the data was loaded correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "\n",
      "Validation loader:\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([1, 1024]) torch.Size([1, 1024])\n",
      "51\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for x, y in train_loader:\n",
    "    print(x.shape, y.shape)\n",
    "\n",
    "print(\"\\nValidation loader:\")\n",
    "for x, y in val_loader:\n",
    "    print(x.shape, y.shape)\n",
    "\n",
    "print(len(train_loader))\n",
    "print(len(val_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### An optional check that the data was loaded correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training tokens: 104448\n",
      "Validation tokens: 11264\n",
      "All tokens: 115712\n"
     ]
    }
   ],
   "source": [
    "train_tokens = 0\n",
    "for input_batch, target_batch in train_loader:\n",
    "    train_tokens += input_batch.numel()\n",
    "\n",
    "val_tokens = 0\n",
    "for input_batch, target_batch in val_loader:\n",
    "    val_tokens += input_batch.numel()\n",
    "\n",
    "print(\"Training tokens:\", train_tokens)\n",
    "print(\"Validation tokens:\", val_tokens)\n",
    "print(\"All tokens:\", train_tokens + val_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 10.944752655777277\n",
      "Validation loss: 10.954849243164062\n",
      "\n",
      "\n",
      "Training completed in 0.21 minutes.\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model.to(device) # no assignment model = model.to(device) necessary for nn.Module classes\n",
    "\n",
    "torch.manual_seed(2010027) # For reproducibility due to the shuffling in the data loader\n",
    "\n",
    "with torch.no_grad(): # Disable gradient tracking for efficiency because we are not training, yet\n",
    "    train_loss = calc_loss_loader(train_loader, model, device)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device)\n",
    "\n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)\n",
    "\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(\"\\n\")\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Training Loop for LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
    "                       eval_freq, eval_iter, start_context, tokenizer):\n",
    "    # Initialize lists to track losses and tokens seen\n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
    "    tokens_seen, global_step = 0, -1\n",
    "\n",
    "    # Main training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Set model to training mode\n",
    "        \n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad() # Reset loss gradients from previous batch iteration\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward() # Calculate loss gradients\n",
    "            optimizer.step() # Update model weights using loss gradients\n",
    "            tokens_seen += input_batch.numel() # Returns the total number of elements (or tokens) in the input_batch.\n",
    "            global_step += 1\n",
    "\n",
    "            # Optional evaluation step\n",
    "            if global_step % eval_freq == 0: \n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(f\"Epoch {epoch+1} (Step {global_step:06d}): \"\n",
    "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
    "\n",
    "        # Print a sample text after each epoch\n",
    "        generate_and_print_sample(\n",
    "            model, tokenizer, device, start_context\n",
    "        )\n",
    "\n",
    "    return train_losses, val_losses, track_tokens_seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "The evaluate_model function calculates the loss over the training and validation set while ensuring the model is in evaluation mode with gradient tracking and dropout disabled when calculating the loss over the training and validation sets.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "    model.eval()\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate_text_simple(\n",
    "            model=model, idx=encoded,\n",
    "            max_new_tokens=50, context_size=context_size\n",
    "        )\n",
    "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    print(decoded_text.replace(\"\\n\", \" \"))  # Compact print format\n",
    "    print(\"\\n\")\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "The generate_and_print_sample function is a convenience function that we use to track whether the model improves during the training. \n",
    "\n",
    "In particular, the generate_and_print_sample function takes a text snippet (start_context) as input, converts it into token IDs, and feeds it to the LLM to generate a text sample using the generate_text_simple function used earlier.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 (Step 000000): Train loss 9.498, Val loss 9.467\n",
      "Epoch 1 (Step 000005): Train loss 8.623, Val loss 8.544\n",
      "Epoch 1 (Step 000010): Train loss 8.217, Val loss 8.199\n",
      "Epoch 1 (Step 000015): Train loss 7.927, Val loss 7.865\n",
      "Epoch 1 (Step 000020): Train loss 7.609, Val loss 7.563\n",
      "Epoch 1 (Step 000025): Train loss 7.335, Val loss 7.314\n",
      "Epoch 1 (Step 000030): Train loss 7.199, Val loss 7.056\n",
      "Epoch 1 (Step 000035): Train loss 6.792, Val loss 6.827\n",
      "Epoch 1 (Step 000040): Train loss 6.617, Val loss 6.662\n",
      "Epoch 1 (Step 000045): Train loss 6.477, Val loss 6.503\n",
      "Epoch 1 (Step 000050): Train loss 6.280, Val loss 6.369\n",
      "Every effort moves you, and the     \"I, and the  \"I, and the \"I, and the \"I the  \" \"I, and the \"  \"I, and the \"\n",
      "\n",
      "\n",
      "Epoch 2 (Step 000055): Train loss 6.354, Val loss 6.315\n",
      "Epoch 2 (Step 000060): Train loss 5.980, Val loss 6.240\n",
      "Epoch 2 (Step 000065): Train loss 5.976, Val loss 6.085\n",
      "Epoch 2 (Step 000070): Train loss 5.878, Val loss 6.056\n",
      "Epoch 2 (Step 000075): Train loss 5.929, Val loss 5.999\n",
      "Epoch 2 (Step 000080): Train loss 5.628, Val loss 5.909\n",
      "Epoch 2 (Step 000085): Train loss 5.716, Val loss 5.859\n",
      "Epoch 2 (Step 000090): Train loss 5.600, Val loss 5.794\n",
      "Epoch 2 (Step 000095): Train loss 5.602, Val loss 5.737\n",
      "Epoch 2 (Step 000100): Train loss 5.523, Val loss 5.694\n",
      "Every effort moves you  \"I'm't you,  \"I'm the \"I'm \"I'm, and \"You, \"I'm the \"I'm, \"I'm, and \"I'm, \"\n",
      "\n",
      "\n",
      "Epoch 3 (Step 000105): Train loss 5.354, Val loss 5.675\n",
      "Epoch 3 (Step 000110): Train loss 5.439, Val loss 5.648\n",
      "Epoch 3 (Step 000115): Train loss 5.227, Val loss 5.613\n",
      "Epoch 3 (Step 000120): Train loss 5.274, Val loss 5.598\n",
      "Epoch 3 (Step 000125): Train loss 5.197, Val loss 5.573\n",
      "Epoch 3 (Step 000130): Train loss 5.165, Val loss 5.572\n",
      "Epoch 3 (Step 000135): Train loss 5.186, Val loss 5.548\n",
      "Epoch 3 (Step 000140): Train loss 5.088, Val loss 5.534\n",
      "Epoch 3 (Step 000145): Train loss 5.160, Val loss 5.511\n",
      "Epoch 3 (Step 000150): Train loss 4.960, Val loss 5.488\n",
      "Every effort moves you  \"I'm going to the  \"I'm not to be in the \"I'm not to the \"I'm not to the \"I'm not to \"I'm going to the \"I'm not\n",
      "\n",
      "\n",
      "Epoch 4 (Step 000155): Train loss 4.935, Val loss 5.497\n",
      "Epoch 4 (Step 000160): Train loss 4.858, Val loss 5.482\n",
      "Epoch 4 (Step 000165): Train loss 4.694, Val loss 5.482\n",
      "Epoch 4 (Step 000170): Train loss 4.825, Val loss 5.467\n",
      "Epoch 4 (Step 000175): Train loss 4.822, Val loss 5.441\n",
      "Epoch 4 (Step 000180): Train loss 4.825, Val loss 5.446\n",
      "Epoch 4 (Step 000185): Train loss 4.665, Val loss 5.440\n",
      "Epoch 4 (Step 000190): Train loss 4.638, Val loss 5.417\n",
      "Epoch 4 (Step 000195): Train loss 4.565, Val loss 5.396\n",
      "Epoch 4 (Step 000200): Train loss 4.507, Val loss 5.389\n",
      "Every effort moves you  \"I'm going to the  \"I'm not to the   \"I'm not to the \"I'm not the \"I'm not, I've got to the    \"I'm not\n",
      "\n",
      "\n",
      "Epoch 5 (Step 000205): Train loss 4.500, Val loss 5.394\n",
      "Epoch 5 (Step 000210): Train loss 4.548, Val loss 5.386\n",
      "Epoch 5 (Step 000215): Train loss 4.433, Val loss 5.373\n",
      "Epoch 5 (Step 000220): Train loss 4.373, Val loss 5.379\n",
      "Epoch 5 (Step 000225): Train loss 4.376, Val loss 5.381\n",
      "Epoch 5 (Step 000230): Train loss 4.383, Val loss 5.372\n",
      "Epoch 5 (Step 000235): Train loss 4.245, Val loss 5.361\n",
      "Epoch 5 (Step 000240): Train loss 4.190, Val loss 5.367\n",
      "Epoch 5 (Step 000245): Train loss 4.103, Val loss 5.351\n",
      "Epoch 5 (Step 000250): Train loss 4.071, Val loss 5.346\n",
      "Every effort moves you \"What's not to be in the \"I've got to be in the  \"I'm not to see you,  \"You're not in the \"I've got to see you're not \" \"\n",
      "\n",
      "\n",
      "Epoch 6 (Step 000255): Train loss 4.240, Val loss 5.336\n",
      "Epoch 6 (Step 000260): Train loss 4.131, Val loss 5.361\n",
      "Epoch 6 (Step 000265): Train loss 4.003, Val loss 5.346\n",
      "Epoch 6 (Step 000270): Train loss 4.193, Val loss 5.368\n",
      "Epoch 6 (Step 000275): Train loss 4.070, Val loss 5.368\n",
      "Epoch 6 (Step 000280): Train loss 3.944, Val loss 5.349\n",
      "Epoch 6 (Step 000285): Train loss 3.918, Val loss 5.356\n",
      "Epoch 6 (Step 000290): Train loss 3.863, Val loss 5.356\n",
      "Epoch 6 (Step 000295): Train loss 3.795, Val loss 5.310\n",
      "Epoch 6 (Step 000300): Train loss 3.751, Val loss 5.310\n",
      "Epoch 6 (Step 000305): Train loss 3.921, Val loss 5.295\n",
      "Every effort moves you  \"I'm not to the \"I'm not going to get him, \"I'm not \"What's \"I'm not to do, I've got to  \"I'm not,\" said Hermione. \"\n",
      "\n",
      "\n",
      "Epoch 7 (Step 000310): Train loss 3.737, Val loss 5.327\n",
      "Epoch 7 (Step 000315): Train loss 3.682, Val loss 5.333\n",
      "Epoch 7 (Step 000320): Train loss 3.742, Val loss 5.348\n",
      "Epoch 7 (Step 000325): Train loss 3.664, Val loss 5.360\n",
      "Epoch 7 (Step 000330): Train loss 3.684, Val loss 5.346\n",
      "Epoch 7 (Step 000335): Train loss 3.635, Val loss 5.344\n",
      "Epoch 7 (Step 000340): Train loss 3.621, Val loss 5.351\n",
      "Epoch 7 (Step 000345): Train loss 3.666, Val loss 5.348\n",
      "Epoch 7 (Step 000350): Train loss 3.447, Val loss 5.369\n",
      "Epoch 7 (Step 000355): Train loss 3.574, Val loss 5.341\n",
      "Every effort moves you all \"I'm not to \"What's the way.  \"What's the next to be able to the    \"What's a small, I've got the door and Ron's the    \"\n",
      "\n",
      "\n",
      "Epoch 8 (Step 000360): Train loss 3.442, Val loss 5.359\n",
      "Epoch 8 (Step 000365): Train loss 3.467, Val loss 5.367\n",
      "Epoch 8 (Step 000370): Train loss 3.402, Val loss 5.389\n",
      "Epoch 8 (Step 000375): Train loss 3.418, Val loss 5.408\n",
      "Epoch 8 (Step 000380): Train loss 3.335, Val loss 5.394\n",
      "Epoch 8 (Step 000385): Train loss 3.228, Val loss 5.413\n",
      "Epoch 8 (Step 000390): Train loss 3.198, Val loss 5.372\n",
      "Epoch 8 (Step 000395): Train loss 3.397, Val loss 5.380\n",
      "Epoch 8 (Step 000400): Train loss 3.264, Val loss 5.371\n",
      "Epoch 8 (Step 000405): Train loss 3.199, Val loss 5.379\n",
      "Every effort moves you had a \"I've got the  \"I want you to get a small voice.  \"I've been?\" said Ron. \"I'm not,\" said Ron, I've been in the way,    \"\n",
      "\n",
      "\n",
      "Epoch 9 (Step 000410): Train loss 3.065, Val loss 5.417\n",
      "Epoch 9 (Step 000415): Train loss 3.125, Val loss 5.444\n",
      "Epoch 9 (Step 000420): Train loss 3.083, Val loss 5.449\n",
      "Epoch 9 (Step 000425): Train loss 2.965, Val loss 5.451\n",
      "Epoch 9 (Step 000430): Train loss 3.052, Val loss 5.461\n",
      "Epoch 9 (Step 000435): Train loss 3.002, Val loss 5.456\n",
      "Epoch 9 (Step 000440): Train loss 2.931, Val loss 5.497\n",
      "Epoch 9 (Step 000445): Train loss 2.888, Val loss 5.452\n",
      "Epoch 9 (Step 000450): Train loss 2.874, Val loss 5.457\n",
      "Epoch 9 (Step 000455): Train loss 2.851, Val loss 5.440\n",
      "Every effort moves you had a \"Well, I'm not a lot of course, I'm not  \"I don't know, I'm not to be able to get \"What's that's. \"I don't know, I'm warning\n",
      "\n",
      "\n",
      "Epoch 10 (Step 000460): Train loss 2.766, Val loss 5.480\n",
      "Epoch 10 (Step 000465): Train loss 2.822, Val loss 5.528\n",
      "Epoch 10 (Step 000470): Train loss 2.803, Val loss 5.507\n",
      "Epoch 10 (Step 000475): Train loss 2.678, Val loss 5.560\n",
      "Epoch 10 (Step 000480): Train loss 2.623, Val loss 5.568\n",
      "Epoch 10 (Step 000485): Train loss 2.642, Val loss 5.525\n",
      "Epoch 10 (Step 000490): Train loss 2.735, Val loss 5.546\n",
      "Epoch 10 (Step 000495): Train loss 2.653, Val loss 5.526\n",
      "Epoch 10 (Step 000500): Train loss 2.782, Val loss 5.535\n",
      "Epoch 10 (Step 000505): Train loss 2.460, Val loss 5.537\n",
      "Every effort moves you had a very last, and Ron.  \"I'm not to be so much as she said Ron. \"I'm not to his name, I'm not to \"   \"We've been on the three of the wall\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training completed in 10.14 minutes.\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "torch.manual_seed(2010027)\n",
    "model = GPTModel(GPT_CONFIG_774M)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.00005, weight_decay=0.1)\n",
    "\n",
    "num_epochs = 10\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
    "    start_context=\"Every effort moves you\", tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(\"\\n\")\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    fig, ax1 = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "    # Plot training and validation loss against epochs\n",
    "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
    "    ax1.plot(epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))  # only show integer labels on x-axis\n",
    "\n",
    "    # Create a second x-axis for tokens seen\n",
    "    ax2 = ax1.twiny()  # Create a second x-axis that shares the same y-axis\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0)  # Invisible plot for aligning ticks\n",
    "    ax2.set_xlabel(\"Tokens seen\")\n",
    "\n",
    "    fig.tight_layout()  # Adjust layout to make room\n",
    "    plt.savefig(\"loss-plot.pdf\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "Both the training and validation losses start to improve for the first epoch. However, the losses start to diverge past the second epoch. \n",
    "\n",
    "This divergence and the fact that the validation loss is much larger than the training loss indicate that the model is overfitting to the training data. \n",
    "\n",
    "The model memorizes the training data. This memorization is expected since a VERY, VERY SMALL training dataset is ised and trained the model for multiple epochs. \n",
    "\n",
    "Usually, it's common to train a model on a MUCH, MUCH LARGER dataset for only one epoch.   \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Decoding Strategy To Control Randomness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temperature Scaling with Top-k Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model, idx, max_new_tokens, context_size, temperature=0.0, top_k=None, eos_id=None):\n",
    "\n",
    "    # For-loop is the same as before: Get logits, and only focus on last time step\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        logits = logits[:, -1, :]\n",
    "\n",
    "        # New: Filter logits with top_k sampling\n",
    "        if top_k is not None:\n",
    "            # Keep only top_k values\n",
    "            top_logits, _ = torch.topk(logits, top_k)\n",
    "            min_val = top_logits[:, -1]\n",
    "            logits = torch.where(logits < min_val, torch.tensor(float(\"-inf\")).to(logits.device), logits)\n",
    "\n",
    "        # New: Apply temperature scaling\n",
    "        if temperature > 0.0:\n",
    "            logits = logits / temperature\n",
    "\n",
    "            # Apply softmax to get probabilities\n",
    "            probs = torch.softmax(logits, dim=-1)  # (batch_size, context_len)\n",
    "\n",
    "            # Sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)  # (batch_size, 1)\n",
    "\n",
    "        # Otherwise same as before: get idx of the vocab entry with the highest logits value\n",
    "        else:\n",
    "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)  # (batch_size, 1)\n",
    "\n",
    "        if idx_next == eos_id:  # Stop generating early if end-of-sequence token is encountered and eos_id is specified\n",
    "            break\n",
    "\n",
    "        # Same as before: append sampled index to the running sequence\n",
    "        idx = torch.cat((idx, idx_next), dim=1)  # (batch_size, num_tokens+1)\n",
    "\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you- a very hard to\n",
      "and the room. There was up!\"\n",
      "\n",
      "They left as the room than a pair of his mother. Ron's\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model=model.to(device)\n",
    "\n",
    "\n",
    "torch.manual_seed(2010027)\n",
    "\n",
    "token_ids = generate(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer).to(device),\n",
    "    max_new_tokens=30,\n",
    "    context_size=GPT_CONFIG_774M[\"context_length\"],\n",
    "    top_k=25,\n",
    "    temperature=1.4\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "The generated text is very different from the one previously generated.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Loading and Saving Model Wights in Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GPTModel(GPT_CONFIG_774M)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.00005, weight_decay=0.1)\n",
    "\n",
    "torch.save({\n",
    "    \"model_state_dict\": model.state_dict(),\n",
    "    \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "    }, \n",
    "    \"model_and_optimizer.pth\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "To continue pretraining a model later, for example, using the train_model_simple function defined earlier, saving the optimizer state is also recommended.\n",
    "\n",
    "Adaptive optimizers such as AdamW store additional parameters for each model weight. AdamW uses historical data to adjust learning rates for each model parameter dynamically.\n",
    "                                                   \n",
    "Without it, the optimizer resets, and the model may learn suboptimally or even fail to converge properly, which means that it will lose the ability to generate coherent text. \n",
    "\n",
    "Using torch.save, save both the model and optimizer state_dict contents.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 1280)\n",
       "  (pos_emb): Embedding(1024, 1280)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (12): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (13): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (14): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (15): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (16): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (17): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (18): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (19): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (20): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (21): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (22): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (23): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (24): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (25): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (26): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (27): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (28): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (29): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (30): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (31): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (32): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (33): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (34): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (35): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=1280, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load(\"model_and_optimizer.pth\")\n",
    "\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "\n",
    "model.eval()\n",
    "\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 2: Foundation Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretrained Weights from OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.18.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorflow) (2.1.0)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow)\n",
      "  Downloading flatbuffers-24.12.23-py2.py3-none-any.whl.metadata (876 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
      "  Downloading gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\n",
      "  Downloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow)\n",
      "  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorflow) (24.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorflow) (4.23.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorflow) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorflow) (4.12.2)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow)\n",
      "  Downloading wrapt-1.17.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorflow) (1.68.1)\n",
      "Collecting tensorboard<2.19,>=2.18 (from tensorflow)\n",
      "  Downloading tensorboard-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting keras>=3.5.0 (from tensorflow)\n",
      "  Downloading keras-3.8.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorflow) (1.26.4)\n",
      "Collecting h5py>=3.11.0 (from tensorflow)\n",
      "  Downloading h5py-3.12.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\n",
      "Collecting ml-dtypes<0.5.0,>=0.4.0 (from tensorflow)\n",
      "  Downloading ml_dtypes-0.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow)\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.37.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
      "Requirement already satisfied: rich in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
      "Collecting namex (from keras>=3.5.0->tensorflow)\n",
      "  Downloading namex-0.0.8-py3-none-any.whl.metadata (246 bytes)\n",
      "Collecting optree (from keras>=3.5.0->tensorflow)\n",
      "  Downloading optree-0.13.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (47 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.12.14)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
      "Downloading tensorflow-2.18.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (615.3 MB)\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.3/615.3 MB\u001b[0m \u001b[31m207.6 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m615.3/615.3 MB\u001b[0m \u001b[31m109.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading flatbuffers-24.12.23-py2.py3-none-any.whl (30 kB)\n",
      "Downloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Downloading h5py-3.12.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m200.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading keras-3.8.0-py3-none-any.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m151.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.5/24.5 MB\u001b[0m \u001b[31m213.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ml_dtypes-0.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m173.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Downloading tensorboard-2.18.0-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m183.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorflow_io_gcs_filesystem-0.37.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m169.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading wrapt-1.17.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (82 kB)\n",
      "Downloading namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
      "Downloading optree-0.13.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (381 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, wrapt, tensorflow-io-gcs-filesystem, optree, opt-einsum, ml-dtypes, h5py, google-pasta, gast, astunparse, tensorboard, keras, tensorflow\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.15.1\n",
      "    Uninstalling tensorboard-2.15.1:\n",
      "      Successfully uninstalled tensorboard-2.15.1\n",
      "Successfully installed astunparse-1.6.3 flatbuffers-24.12.23 gast-0.6.0 google-pasta-0.2.0 h5py-3.12.1 keras-3.8.0 libclang-18.1.1 ml-dtypes-0.4.1 namex-0.0.8 opt-einsum-3.4.0 optree-0.13.1 tensorboard-2.18.0 tensorflow-2.18.0 tensorflow-io-gcs-filesystem-0.37.1 wrapt-1.17.1\n",
      "Requirement already satisfied: tqdm in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (4.67.1)\n"
     ]
    }
   ],
   "source": [
    "! pip install tensorflow \n",
    "! pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-12 14:14:41.313433: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1736691281.347217    1874 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1736691281.356712    1874 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-01-12 14:14:41.436538: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tqdm\n",
    "import requests\n",
    "from gpt_download3 import download_and_load_gpt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.18.0\n",
      "tqdm version: 4.67.1\n"
     ]
    }
   ],
   "source": [
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"tqdm version:\", tqdm.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "checkpoint: 100%|██████████| 77.0/77.0 [00:00<00:00, 171kiB/s]\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "encoder.json:   0%|          | 0.00/1.04M [00:00<?, ?iB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "encoder.json: 100%|██████████| 1.04M/1.04M [00:00<00:00, 4.37MiB/s]\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "hparams.json: 100%|██████████| 91.0/91.0 [00:00<00:00, 232kiB/s]\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "model.ckpt.data-00000-of-00001: 100%|██████████| 3.10G/3.10G [02:01<00:00, 25.5MiB/s]\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "model.ckpt.index: 100%|██████████| 15.5k/15.5k [00:00<00:00, 24.5MiB/s]\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "model.ckpt.meta: 100%|██████████| 1.38M/1.38M [00:00<00:00, 4.66MiB/s]\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "vocab.bpe: 100%|██████████| 456k/456k [00:00<00:00, 2.83MiB/s]\n"
     ]
    }
   ],
   "source": [
    "settings, params = download_and_load_gpt2(model_size=\"774M\", models_dir=\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Settings: {'n_vocab': 50257, 'n_ctx': 1024, 'n_embd': 1280, 'n_head': 20, 'n_layer': 36}\n",
      "Parameter dictionary keys: dict_keys(['blocks', 'b', 'g', 'wpe', 'wte'])\n"
     ]
    }
   ],
   "source": [
    "print(\"Settings:\", settings)\n",
    "print(\"Parameter dictionary keys:\", params.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 1280)\n",
       "  (pos_emb): Embedding(1024, 1280)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (12): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (13): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (14): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (15): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (16): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (17): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (18): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (19): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (20): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (21): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (22): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (23): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (24): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (25): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (26): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (27): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (28): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (29): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (30): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (31): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (32): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (33): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (34): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (35): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=1280, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define model configurations in a dictionary for compactness\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "# Copy the base configuration and update with specific model settings\n",
    "model_name = \"gpt2-large (774M)\"\n",
    "NEW_CONFIG = GPT_CONFIG_774M.copy()\n",
    "NEW_CONFIG.update(model_configs[model_name])\n",
    "\n",
    "\n",
    "NEW_CONFIG.update({\"context_length\": 1024, \"qkv_bias\": True})\n",
    "gpt = GPTModel(NEW_CONFIG)\n",
    "gpt.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign(left, right):\n",
    "    if left.shape != right.shape:\n",
    "        raise ValueError(f\"Shape mismatch. Left: {left.shape}, Right: {right.shape}\")\n",
    "    return torch.nn.Parameter(torch.tensor(right))\n",
    "\n",
    "\n",
    "def load_weights_into_gpt(gpt, params):\n",
    "    gpt.pos_emb.weight = assign(gpt.pos_emb.weight, params['wpe'])\n",
    "    gpt.tok_emb.weight = assign(gpt.tok_emb.weight, params['wte'])\n",
    "    \n",
    "    for b in range(len(params[\"blocks\"])):\n",
    "        q_w, k_w, v_w = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"w\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].att.W_query.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_query.weight, q_w.T)\n",
    "        gpt.trf_blocks[b].att.W_key.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_key.weight, k_w.T)\n",
    "        gpt.trf_blocks[b].att.W_value.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.weight, v_w.T)\n",
    "\n",
    "        q_b, k_b, v_b = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"b\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].att.W_query.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_query.bias, q_b)\n",
    "        gpt.trf_blocks[b].att.W_key.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_key.bias, k_b)\n",
    "        gpt.trf_blocks[b].att.W_value.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.bias, v_b)\n",
    "\n",
    "        gpt.trf_blocks[b].att.out_proj.weight = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.weight, \n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].att.out_proj.bias = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.bias, \n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"])\n",
    "\n",
    "        gpt.trf_blocks[b].ff.layers[0].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].weight, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[0].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].bias, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"])\n",
    "        gpt.trf_blocks[b].ff.layers[2].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].weight, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[2].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].bias, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"])\n",
    "\n",
    "        gpt.trf_blocks[b].norm1.scale = assign(\n",
    "            gpt.trf_blocks[b].norm1.scale, \n",
    "            params[\"blocks\"][b][\"ln_1\"][\"g\"])\n",
    "        gpt.trf_blocks[b].norm1.shift = assign(\n",
    "            gpt.trf_blocks[b].norm1.shift, \n",
    "            params[\"blocks\"][b][\"ln_1\"][\"b\"])\n",
    "        gpt.trf_blocks[b].norm2.scale = assign(\n",
    "            gpt.trf_blocks[b].norm2.scale, \n",
    "            params[\"blocks\"][b][\"ln_2\"][\"g\"])\n",
    "        gpt.trf_blocks[b].norm2.shift = assign(\n",
    "            gpt.trf_blocks[b].norm2.shift, \n",
    "            params[\"blocks\"][b][\"ln_2\"][\"b\"])\n",
    "\n",
    "    gpt.final_norm.scale = assign(gpt.final_norm.scale, params[\"g\"])\n",
    "    gpt.final_norm.shift = assign(gpt.final_norm.shift, params[\"b\"])\n",
    "    gpt.out_head.weight = assign(gpt.out_head.weight, params[\"wte\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 1280)\n",
       "  (pos_emb): Embedding(1024, 1280)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (12): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (13): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (14): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (15): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (16): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (17): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (18): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (19): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (20): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (21): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (22): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (23): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (24): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (25): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (26): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (27): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (28): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (29): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (30): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (31): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (32): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (33): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (34): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (35): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=1280, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_weights_into_gpt(gpt, params)\n",
    "gpt.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you to this point and to one that will create new challenges. To learn something new, to expand or to improve your talent,\n",
      "/n\n",
      "Training completed in 0.01 minutes.\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "\n",
    "torch.manual_seed(2010027)\n",
    "\n",
    "token_ids = generate(\n",
    "    model=gpt,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer).to(device),\n",
    "    max_new_tokens=25,\n",
    "    context_size=NEW_CONFIG[\"context_length\"],\n",
    "    top_k=50,\n",
    "    temperature=1.4\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))\n",
    "\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(\"/n\")\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "Text Completition Response of Foundation Model\n",
    "\n",
    "</dev>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 3: Classification Finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import ssl\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Downloading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path):\n",
    "    if data_file_path.exists():\n",
    "        print(f\"{data_file_path} already exists. Skipping download and extraction.\")\n",
    "        return\n",
    "\n",
    "    # Create an unverified SSL context\n",
    "    ssl_context = ssl._create_unverified_context()\n",
    "\n",
    "    # Downloading the file\n",
    "    with urllib.request.urlopen(url, context=ssl_context) as response:\n",
    "        with open(zip_path, \"wb\") as out_file:\n",
    "            out_file.write(response.read())\n",
    "\n",
    "    # Unzipping the file\n",
    "    with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
    "        zip_ref.extractall(extracted_path)\n",
    "\n",
    "    # Add .tsv file extension\n",
    "    original_file_path = Path(extracted_path) / \"SMSSpamCollection\"\n",
    "    os.rename(original_file_path, data_file_path)\n",
    "    print(f\"File downloaded and saved as {data_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File downloaded and saved as /teamspace/studios/this_studio/sms_spam_collection/SMSSpamCollection.tsv\n"
     ]
    }
   ],
   "source": [
    "url = \"https://archive.ics.uci.edu/static/public/228/sms+spam+collection.zip\"\n",
    "zip_path = \"/teamspace/studios/this_studio/sms_spam_collection.zip\"\n",
    "extracted_path = \"/teamspace/studios/this_studio/sms_spam_collection\"\n",
    "data_file_path = Path(extracted_path) / \"SMSSpamCollection.tsv\"\n",
    "\n",
    "download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will ü b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Label                                               Text\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
       "...    ...                                                ...\n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
       "5568   ham               Will ü b going to esplanade fr home?\n",
       "5569   ham  Pity, * was in mood for that. So...any other s...\n",
       "5570   ham  The guy did some bitching but I acted like i'd...\n",
       "5571   ham                         Rofl. Its true to its name\n",
       "\n",
       "[5572 rows x 2 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(data_file_path, sep=\"\\t\", header=None, names=[\"Label\", \"Text\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\n",
      "ham     4825\n",
      "spam     747\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df[\"Label\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "For simplicity and making it possible to finetune the LLM faster, subsample (undersample) the dataset so that it contains 747 instances from each class:\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_balanced_dataset(df):\n",
    "    \n",
    "    # Count the instances of \"spam\"\n",
    "    num_spam = df[df[\"Label\"] == \"spam\"].shape[0]\n",
    "    \n",
    "    # Randomly sample \"ham\" instances to match the number of \"spam\" instances\n",
    "    ham_subset = df[df[\"Label\"] == \"ham\"].sample(num_spam, random_state=2010027)\n",
    "    \n",
    "    # Combine ham \"subset\" with \"spam\"\n",
    "    balanced_df = pd.concat([ham_subset, df[df[\"Label\"] == \"spam\"]])\n",
    "\n",
    "    return balanced_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\n",
      "ham     747\n",
      "spam    747\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "balanced_df = create_balanced_dataset(df)\n",
    "print(balanced_df[\"Label\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "Next, the \"string\" class labels \"ham\" and \"spam\" into integer class labels 0 and 1, respectively:\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_df[\"Label\"] = balanced_df[\"Label\"].map({\"ham\": 0, \"spam\": 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_split(df, train_frac, validation_frac):\n",
    "    # Shuffle the entire DataFrame\n",
    "    df = df.sample(frac=1, random_state=2010027).reset_index(drop=True)\n",
    "\n",
    "    # Calculate split indices\n",
    "    train_end = int(len(df) * train_frac)\n",
    "    validation_end = train_end + int(len(df) * validation_frac)\n",
    "\n",
    "    # Split the DataFrame\n",
    "    train_df = df[:train_end]\n",
    "    validation_df = df[train_end:validation_end]\n",
    "    test_df = df[validation_end:]\n",
    "\n",
    "    return train_df, validation_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, validation_df, test_df = random_split(balanced_df, 0.7, 0.1) # Test size is implied to be 0.2 as the remainder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1045\n",
      "149\n",
      "300\n"
     ]
    }
   ],
   "source": [
    "print(len(train_df))\n",
    "print(len(validation_df))\n",
    "print(len(test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv(\"train.csv\", index=None)\n",
    "validation_df.to_csv(\"validation.csv\", index=None)\n",
    "test_df.to_csv(\"test.csv\", index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Creating Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpamDataset(Dataset):\n",
    "    def __init__(self, csv_file, tokenizer, max_length=None, pad_token_id=50256):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "\n",
    "        # Pre-tokenize texts\n",
    "        self.encoded_texts = [\n",
    "            tokenizer.encode(text) for text in self.data[\"Text\"]\n",
    "        ]\n",
    "\n",
    "        if max_length is None:\n",
    "            self.max_length = self._longest_encoded_length()\n",
    "        else:\n",
    "            self.max_length = max_length\n",
    "            \n",
    "            # Truncate sequences if they are longer than max_length\n",
    "            self.encoded_texts = [\n",
    "                encoded_text[:self.max_length]\n",
    "                for encoded_text in self.encoded_texts\n",
    "            ]\n",
    "\n",
    "        # Pad sequences to the longest sequence\n",
    "        self.encoded_texts = [\n",
    "            encoded_text + [pad_token_id] * (self.max_length - len(encoded_text))\n",
    "            for encoded_text in self.encoded_texts\n",
    "        ]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        encoded = self.encoded_texts[index]\n",
    "        label = self.data.iloc[index][\"Label\"]\n",
    "        return (\n",
    "            torch.tensor(encoded, dtype=torch.long),\n",
    "            torch.tensor(label, dtype=torch.long)\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def _longest_encoded_length(self):\n",
    "        max_length = 0\n",
    "        for encoded_text in self.encoded_texts:\n",
    "            encoded_length = len(encoded_text)\n",
    "            if encoded_length > max_length:\n",
    "                max_length = encoded_length\n",
    "        return max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204\n",
      "204\n",
      "204\n"
     ]
    }
   ],
   "source": [
    "train_dataset = SpamDataset(\n",
    "    csv_file=\"train.csv\",\n",
    "    max_length=None,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "val_dataset = SpamDataset(\n",
    "    csv_file=\"validation.csv\",\n",
    "    max_length=train_dataset.max_length,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "test_dataset = SpamDataset(\n",
    "    csv_file=\"test.csv\",\n",
    "    max_length=train_dataset.max_length,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "print(train_dataset.max_length)\n",
    "print(val_dataset.max_length)\n",
    "print(test_dataset.max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95 training batches\n",
      "14 validation batches\n",
      "28 test batches\n"
     ]
    }
   ],
   "source": [
    "num_workers = 0\n",
    "batch_size = 11\n",
    "\n",
    "torch.manual_seed(2010027)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=True,\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    dataset=val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=False,\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=False,\n",
    ")\n",
    "\n",
    "print(f\"{len(train_loader)} training batches\")\n",
    "print(f\"{len(val_loader)} validation batches\")\n",
    "print(f\"{len(test_loader)} test batches\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Initializing a Model with Pretrained Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHOOSE_MODEL = \"gpt2-large (774M)\"\n",
    "INPUT_PROMPT = \"Every effort moves you\"\n",
    "\n",
    "BASE_CONFIG = {\n",
    "    \"vocab_size\": 50257,     # Vocabulary size\n",
    "    \"context_length\": 1024,  # Context length\n",
    "    \"drop_rate\": 0.0,        # Dropout rate\n",
    "    \"qkv_bias\": True         # Query-key-value bias\n",
    "}\n",
    "\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
    "\n",
    "assert train_dataset.max_length <= BASE_CONFIG[\"context_length\"], (\n",
    "    f\"Dataset length {train_dataset.max_length} exceeds model's context \"\n",
    "    f\"length {BASE_CONFIG['context_length']}. Reinitialize data sets with \"\n",
    "    f\"`max_length={BASE_CONFIG['context_length']}`\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2/774M/checkpoint\n",
      "File already exists and is up-to-date: gpt2/774M/encoder.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2/774M/hparams.json\n",
      "File already exists and is up-to-date: gpt2/774M/model.ckpt.data-00000-of-00001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2/774M/model.ckpt.index\n",
      "File already exists and is up-to-date: gpt2/774M/model.ckpt.meta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2/774M/vocab.bpe\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 1280)\n",
       "  (pos_emb): Embedding(1024, 1280)\n",
       "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (12): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (13): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (14): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (15): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (16): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (17): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (18): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (19): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (20): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (21): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (22): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (23): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (24): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (25): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (26): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (27): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (28): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (29): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (30): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (31): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (32): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (33): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (34): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (35): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=1280, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
    "\n",
    "settings, params = download_and_load_gpt2(model_size=model_size, models_dir=\"gpt2\")\n",
    "\n",
    "model = GPTModel(BASE_CONFIG)\n",
    "load_weights_into_gpt(model, params)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every effort moves you forward.\n",
      "\n",
      "\"I'm not going to be a guy who's going to sit back and say, 'I'm not going to do anything\n"
     ]
    }
   ],
   "source": [
    "text_1 = \"Every effort moves you\"\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(text_1, tokenizer),\n",
    "    max_new_tokens=30,\n",
    "    context_size=BASE_CONFIG[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "To ensure that the model was loaded correctly, a cohernt text is generated.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "Before finetuning the model as a spam classifier, let's see if the model can perhaps already classify spam messages by by prompting it with instructions.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is the following text 'spam'? Answer with 'yes' or 'no': 'You are a winner you have been specially selected to receive $1000 cash or a $2000 award.'\n",
      "\n",
      "The following text 'spam'? Answer with 'yes' or 'no': 'You are a winner you have been specially selected to receive\n"
     ]
    }
   ],
   "source": [
    "text_2 = (\n",
    "    \"Is the following text 'spam'? Answer with 'yes' or 'no':\"\n",
    "    \" 'You are a winner you have been specially selected to receive $1000 cash or a $2000 award.'\"\n",
    ")\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(text_2, tokenizer),\n",
    "    max_new_tokens=30,\n",
    "    context_size=BASE_CONFIG[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "Based on the output, it's apparent that the model struggles with following instructions.\n",
    "This is anticipated, as it has undergone only pretraining and lacks instruction-finetuning.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Adding a Classification Head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "To prepare the model for classification fine-tuning, the model is first frozen, which means all layers are made non-trainable.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(2010027)\n",
    "\n",
    "num_classes = 2\n",
    "model.out_head = torch.nn.Linear(in_features=BASE_CONFIG[\"emb_dim\"], out_features=num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "Then, the output layer (model.out_head), which originally maps the layer inputs to 50,257 dimensions (corresponding to the size of the vocabulary), is replaced.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.trf_blocks[-1].parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "for param in model.final_norm.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "Additionally, the last transformer block and the final LayerNorm module, which connects this block to the output layer, are configured to be trainable.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Calculating the Classification Loss and Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accuracy_loader(data_loader, model, device, num_batches=None):\n",
    "    model.eval()\n",
    "    correct_predictions, num_examples = 0, 0\n",
    "\n",
    "    if num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                logits = model(input_batch)[:, -1, :]  # Logits of last output token\n",
    "            predicted_labels = torch.argmax(logits, dim=-1)\n",
    "\n",
    "            num_examples += predicted_labels.shape[0]\n",
    "            correct_predictions += (predicted_labels == target_batch).sum().item()\n",
    "        else:\n",
    "            break\n",
    "    return correct_predictions / num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 51.82%\n",
      "Validation accuracy: 50.91%\n",
      "Test accuracy: 49.09%\n",
      "\n",
      "\n",
      "Training completed in 0.07 minutes.\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model.to(device) # no assignment model = model.to(device) necessary for nn.Module classes\n",
    "\n",
    "torch.manual_seed(2010027) # For reproducibility due to the shuffling in the training data loader\n",
    "\n",
    "train_accuracy = calc_accuracy_loader(train_loader, model, device, num_batches=10)\n",
    "val_accuracy = calc_accuracy_loader(val_loader, model, device, num_batches=10)\n",
    "test_accuracy = calc_accuracy_loader(test_loader, model, device, num_batches=10)\n",
    "\n",
    "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
    "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")\n",
    "\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(\"\\n\")\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "Initial Accuracy\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "    logits = model(input_batch)[:, -1, :]  # Logits of last output token\n",
    "    loss = torch.nn.functional.cross_entropy(logits, target_batch)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        # Reduce the number of batches to match the total number of batches in the data loader\n",
    "        # if num_batches exceeds the number of batches in the data loader\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Finetuning the Model on Supervised Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall the same as `train_model_simple` above\n",
    "def train_classifier_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
    "                            eval_freq, eval_iter):\n",
    "    # Initialize lists to track losses and examples seen\n",
    "    train_losses, val_losses, train_accs, val_accs = [], [], [], []\n",
    "    examples_seen, global_step = 0, -1\n",
    "\n",
    "    # Main training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Set model to training mode\n",
    "\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad() # Reset loss gradients from previous batch iteration\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward() # Calculate loss gradients\n",
    "            optimizer.step() # Update model weights using loss gradients\n",
    "            examples_seen += input_batch.shape[0] # New: track examples instead of tokens \n",
    "            global_step += 1\n",
    "\n",
    "            # Optional evaluation step\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                print(f\"Epoch {epoch+1} (Step {global_step:06d}): \"\n",
    "                      f\"Train loss {train_loss:.3f}, Validation loss {val_loss:.3f}\")\n",
    "\n",
    "        # Calculate accuracy after each epoch\n",
    "        train_accuracy = calc_accuracy_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_accuracy = calc_accuracy_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "        print(f\"Training accuracy: {train_accuracy*100:.2f}% | \", end=\"\")\n",
    "        print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "        print(\"\\n\")         # New Line\n",
    "        train_accs.append(train_accuracy)\n",
    "        val_accs.append(val_accuracy)\n",
    "\n",
    "    return train_losses, val_losses, train_accs, val_accs, examples_seen\n",
    "\n",
    "\n",
    "\n",
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 (Step 000000): Train loss 0.776, Validation loss 0.840\n",
      "Epoch 1 (Step 000005): Train loss 0.668, Validation loss 0.663\n",
      "Epoch 1 (Step 000010): Train loss 0.693, Validation loss 0.652\n",
      "Epoch 1 (Step 000015): Train loss 0.632, Validation loss 0.645\n",
      "Epoch 1 (Step 000020): Train loss 0.637, Validation loss 0.641\n",
      "Epoch 1 (Step 000025): Train loss 0.619, Validation loss 0.626\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 (Step 000030): Train loss 0.604, Validation loss 0.608\n",
      "Epoch 1 (Step 000035): Train loss 0.574, Validation loss 0.591\n",
      "Epoch 1 (Step 000040): Train loss 0.572, Validation loss 0.587\n",
      "Epoch 1 (Step 000045): Train loss 0.501, Validation loss 0.564\n",
      "Epoch 1 (Step 000050): Train loss 0.557, Validation loss 0.554\n",
      "Epoch 1 (Step 000055): Train loss 0.483, Validation loss 0.540\n",
      "Epoch 1 (Step 000060): Train loss 0.475, Validation loss 0.528\n",
      "Epoch 1 (Step 000065): Train loss 0.533, Validation loss 0.584\n",
      "Epoch 1 (Step 000070): Train loss 0.403, Validation loss 0.513\n",
      "Epoch 1 (Step 000075): Train loss 0.492, Validation loss 0.512\n",
      "Epoch 1 (Step 000080): Train loss 0.465, Validation loss 0.503\n",
      "Epoch 1 (Step 000085): Train loss 0.459, Validation loss 0.488\n",
      "Epoch 1 (Step 000090): Train loss 0.407, Validation loss 0.496\n",
      "Training accuracy: 81.82% | Validation accuracy: 80.00%\n",
      "\n",
      "\n",
      "Epoch 2 (Step 000095): Train loss 0.410, Validation loss 0.489\n",
      "Epoch 2 (Step 000100): Train loss 0.453, Validation loss 0.473\n",
      "Epoch 2 (Step 000105): Train loss 0.501, Validation loss 0.524\n",
      "Epoch 2 (Step 000110): Train loss 0.281, Validation loss 0.497\n",
      "Epoch 2 (Step 000115): Train loss 0.406, Validation loss 0.486\n",
      "Epoch 2 (Step 000120): Train loss 0.473, Validation loss 0.493\n",
      "Epoch 2 (Step 000125): Train loss 0.382, Validation loss 0.476\n",
      "Epoch 2 (Step 000130): Train loss 0.354, Validation loss 0.469\n",
      "Epoch 2 (Step 000135): Train loss 0.347, Validation loss 0.506\n",
      "Epoch 2 (Step 000140): Train loss 0.592, Validation loss 0.506\n",
      "Epoch 2 (Step 000145): Train loss 0.270, Validation loss 0.464\n",
      "Epoch 2 (Step 000150): Train loss 0.443, Validation loss 0.464\n",
      "Epoch 2 (Step 000155): Train loss 0.532, Validation loss 0.466\n",
      "Epoch 2 (Step 000160): Train loss 0.374, Validation loss 0.470\n",
      "Epoch 2 (Step 000165): Train loss 0.365, Validation loss 0.456\n",
      "Epoch 2 (Step 000170): Train loss 0.412, Validation loss 0.460\n",
      "Epoch 2 (Step 000175): Train loss 0.440, Validation loss 0.472\n",
      "Epoch 2 (Step 000180): Train loss 0.614, Validation loss 0.459\n",
      "Epoch 2 (Step 000185): Train loss 0.325, Validation loss 0.457\n",
      "Training accuracy: 85.45% | Validation accuracy: 87.27%\n",
      "\n",
      "\n",
      "Epoch 3 (Step 000190): Train loss 0.293, Validation loss 0.440\n",
      "Epoch 3 (Step 000195): Train loss 0.303, Validation loss 0.444\n",
      "Epoch 3 (Step 000200): Train loss 0.361, Validation loss 0.441\n",
      "Epoch 3 (Step 000205): Train loss 0.466, Validation loss 0.435\n",
      "Epoch 3 (Step 000210): Train loss 0.413, Validation loss 0.415\n",
      "Epoch 3 (Step 000215): Train loss 0.257, Validation loss 0.405\n",
      "Epoch 3 (Step 000220): Train loss 0.488, Validation loss 0.418\n",
      "Epoch 3 (Step 000225): Train loss 0.319, Validation loss 0.425\n",
      "Epoch 3 (Step 000230): Train loss 0.318, Validation loss 0.398\n",
      "Epoch 3 (Step 000235): Train loss 0.438, Validation loss 0.367\n",
      "Epoch 3 (Step 000240): Train loss 0.426, Validation loss 0.368\n",
      "Epoch 3 (Step 000245): Train loss 0.291, Validation loss 0.342\n",
      "Epoch 3 (Step 000250): Train loss 0.605, Validation loss 0.354\n",
      "Epoch 3 (Step 000255): Train loss 0.501, Validation loss 0.402\n",
      "Epoch 3 (Step 000260): Train loss 0.242, Validation loss 0.346\n",
      "Epoch 3 (Step 000265): Train loss 0.131, Validation loss 0.304\n",
      "Epoch 3 (Step 000270): Train loss 0.397, Validation loss 0.310\n",
      "Epoch 3 (Step 000275): Train loss 0.247, Validation loss 0.282\n",
      "Epoch 3 (Step 000280): Train loss 0.241, Validation loss 0.294\n",
      "Training accuracy: 94.55% | Validation accuracy: 92.73%\n",
      "\n",
      "\n",
      "Epoch 4 (Step 000285): Train loss 0.144, Validation loss 0.319\n",
      "Epoch 4 (Step 000290): Train loss 0.263, Validation loss 0.268\n",
      "Epoch 4 (Step 000295): Train loss 0.292, Validation loss 0.247\n",
      "Epoch 4 (Step 000300): Train loss 0.259, Validation loss 0.241\n",
      "Epoch 4 (Step 000305): Train loss 0.194, Validation loss 0.248\n",
      "Epoch 4 (Step 000310): Train loss 0.139, Validation loss 0.249\n",
      "Epoch 4 (Step 000315): Train loss 0.231, Validation loss 0.229\n",
      "Epoch 4 (Step 000320): Train loss 0.236, Validation loss 0.219\n",
      "Epoch 4 (Step 000325): Train loss 0.181, Validation loss 0.220\n",
      "Epoch 4 (Step 000330): Train loss 0.221, Validation loss 0.224\n",
      "Epoch 4 (Step 000335): Train loss 0.228, Validation loss 0.216\n",
      "Epoch 4 (Step 000340): Train loss 0.197, Validation loss 0.208\n",
      "Epoch 4 (Step 000345): Train loss 0.145, Validation loss 0.228\n",
      "Epoch 4 (Step 000350): Train loss 0.153, Validation loss 0.205\n",
      "Epoch 4 (Step 000355): Train loss 0.099, Validation loss 0.193\n",
      "Epoch 4 (Step 000360): Train loss 0.158, Validation loss 0.204\n",
      "Epoch 4 (Step 000365): Train loss 0.197, Validation loss 0.204\n",
      "Epoch 4 (Step 000370): Train loss 0.123, Validation loss 0.188\n",
      "Epoch 4 (Step 000375): Train loss 0.185, Validation loss 0.182\n",
      "Training accuracy: 96.36% | Validation accuracy: 94.55%\n",
      "\n",
      "\n",
      "Epoch 5 (Step 000380): Train loss 0.119, Validation loss 0.174\n",
      "Epoch 5 (Step 000385): Train loss 0.249, Validation loss 0.174\n",
      "Epoch 5 (Step 000390): Train loss 0.231, Validation loss 0.203\n",
      "Epoch 5 (Step 000395): Train loss 0.132, Validation loss 0.177\n",
      "Epoch 5 (Step 000400): Train loss 0.158, Validation loss 0.163\n",
      "Epoch 5 (Step 000405): Train loss 0.102, Validation loss 0.173\n",
      "Epoch 5 (Step 000410): Train loss 0.172, Validation loss 0.170\n",
      "Epoch 5 (Step 000415): Train loss 0.167, Validation loss 0.155\n",
      "Epoch 5 (Step 000420): Train loss 0.162, Validation loss 0.169\n",
      "Epoch 5 (Step 000425): Train loss 0.291, Validation loss 0.157\n",
      "Epoch 5 (Step 000430): Train loss 0.218, Validation loss 0.151\n",
      "Epoch 5 (Step 000435): Train loss 0.229, Validation loss 0.170\n",
      "Epoch 5 (Step 000440): Train loss 0.140, Validation loss 0.168\n",
      "Epoch 5 (Step 000445): Train loss 0.160, Validation loss 0.141\n",
      "Epoch 5 (Step 000450): Train loss 0.149, Validation loss 0.139\n",
      "Epoch 5 (Step 000455): Train loss 0.100, Validation loss 0.136\n",
      "Epoch 5 (Step 000460): Train loss 0.176, Validation loss 0.142\n",
      "Epoch 5 (Step 000465): Train loss 0.175, Validation loss 0.133\n",
      "Epoch 5 (Step 000470): Train loss 0.150, Validation loss 0.140\n",
      "Training accuracy: 92.73% | Validation accuracy: 96.36%\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training completed in 3.35 minutes.\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "torch.manual_seed(2010027)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.00005, weight_decay=0.1)\n",
    "\n",
    "train_losses, val_losses, train_accs, val_accs, examples_seen = train_classifier_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
    ")\n",
    "\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(\"\\n\")\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_values(epochs_seen, examples_seen, train_values, val_values, label=\"loss\"):\n",
    "    fig, ax1 = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "    # Plot training and validation loss against epochs\n",
    "    ax1.plot(epochs_seen, train_values, label=f\"Training {label}\")\n",
    "    ax1.plot(epochs_seen, val_values, linestyle=\"-.\", label=f\"Validation {label}\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(label.capitalize())\n",
    "    ax1.legend()\n",
    "\n",
    "    # Create a second x-axis for examples seen\n",
    "    ax2 = ax1.twiny()  # Create a second x-axis that shares the same y-axis\n",
    "    ax2.plot(examples_seen, train_values, alpha=0)  # Invisible plot for aligning ticks\n",
    "    ax2.set_xlabel(\"Examples seen\")\n",
    "\n",
    "    fig.tight_layout()  # Adjust layout to make room\n",
    "    plt.savefig(f\"{label}-plot.pdf\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "examples_seen_tensor = torch.linspace(0, examples_seen, len(train_losses))\n",
    "\n",
    "plot_values(epochs_tensor, examples_seen_tensor, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    \n",
    "Based on the sharp downward slope, the model is learning well from the training data, and there is little to no indication of overfitting; that is, there is no noticeable gap between the training and validation set losses.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_accs))\n",
    "examples_seen_tensor = torch.linspace(0, examples_seen, len(train_accs))\n",
    "\n",
    "plot_values(epochs_tensor, examples_seen_tensor, train_accs, val_accs, label=\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    \n",
    "Based on the accuracy plot, the model achieves a relatively high training and validation accuracy after few epochs.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 95.69%\n",
      "Validation accuracy: 96.64%\n",
      "Test accuracy: 93.67%\n"
     ]
    }
   ],
   "source": [
    "train_accuracy = calc_accuracy_loader(train_loader, model, device)\n",
    "val_accuracy = calc_accuracy_loader(val_loader, model, device)\n",
    "test_accuracy = calc_accuracy_loader(test_loader, model, device)\n",
    "\n",
    "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
    "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "Accuracy after training\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Using the LLM as a Spam Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_review(text, model, tokenizer, device, max_length=None, pad_token_id=50256):\n",
    "    model.eval()\n",
    "\n",
    "    # Prepare inputs to the model\n",
    "    input_ids = tokenizer.encode(text)\n",
    "    supported_context_length = model.pos_emb.weight.shape[0]\n",
    "    # Note: In the book, this was originally written as pos_emb.weight.shape[1] by mistake\n",
    "    # It didn't break the code but would have caused unnecessary truncation (to 768 instead of 1024)\n",
    "\n",
    "    # Truncate sequences if they too long\n",
    "    input_ids = input_ids[:min(max_length, supported_context_length)]\n",
    "\n",
    "    # Pad sequences to the longest sequence\n",
    "    input_ids += [pad_token_id] * (max_length - len(input_ids))\n",
    "    input_tensor = torch.tensor(input_ids, device=device).unsqueeze(0) # add batch dimension\n",
    "\n",
    "    # Model inference\n",
    "    with torch.no_grad():\n",
    "        logits = model(input_tensor)[:, -1, :]  # Logits of the last output token\n",
    "    predicted_label = torch.argmax(logits, dim=-1).item()\n",
    "\n",
    "    # Return the classified result\n",
    "    return \"spam\" if predicted_label == 1 else \"not spam\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not spam\n"
     ]
    }
   ],
   "source": [
    "text_1 = (\n",
    "    \"You are a winner you have been specially selected to receive $1000 cash or a $2000 award.\"\n",
    ")\n",
    "\n",
    "print(classify_review(\n",
    "    text_1, model, tokenizer, device, max_length=train_dataset.max_length\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not spam\n"
     ]
    }
   ],
   "source": [
    "text_2 = (\n",
    "    \"Hey, just wanted to check if we're still on for dinner tonight? Let me know!\"\n",
    ")\n",
    "\n",
    "print(classify_review(\n",
    "    text_2, model, tokenizer, device, max_length=train_dataset.max_length\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    \n",
    "The resulting model correctly predicts \"spam\" and \"not spam\".\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.save(model.state_dict(), \"review_classifier.pth\")\n",
    "\n",
    "model_state_dict = torch.load(\"review_classifier.pth\")\n",
    "model.load_state_dict(model_state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 4.1: Instruction Finetuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Preparing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "from functools import partial\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_and_load_file(file_path, url):\n",
    "    ssl_context = ssl.create_default_context()\n",
    "    ssl_context.check_hostname = False\n",
    "    ssl_context.verify_mode = ssl.CERT_NONE\n",
    "\n",
    "    if not os.path.exists(file_path):\n",
    "        with urllib.request.urlopen(url, context=ssl_context) as response:\n",
    "            text_data = response.read().decode(\"utf-8\")\n",
    "        with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "            file.write(text_data)\n",
    "    else:\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "            text_data = file.read()\n",
    "\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries: 1100\n"
     ]
    }
   ],
   "source": [
    "file_path = \"instruction-data.json\"\n",
    "url = (\n",
    "    \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch07/01_main-chapter-code/instruction-data.json\"\n",
    ")\n",
    "\n",
    "data = download_and_load_file(file_path, url)\n",
    "print(\"Number of entries:\", len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example entry:\n",
      " {'instruction': 'What is the state capital of California?', 'input': '', 'output': 'The state capital of California is Sacramento.'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Example entry:\\n\", data[27])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting Instructions into Alpaca Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_input(entry):\n",
    "    instruction_text = (\n",
    "        f\"Below is an instruction that describes a task. \"\n",
    "        f\"Write a response that appropriately completes the request.\"\n",
    "        f\"\\n\\n### Instruction:\\n{entry['instruction']}\"\n",
    "    )\n",
    "\n",
    "    input_text = f\"\\n\\n### Input:\\n{entry['input']}\" if entry[\"input\"] else \"\"\n",
    "\n",
    "    return instruction_text + input_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What is the state capital of California?\n",
      "\n",
      "### Response:\n",
      "The state capital of California is Sacramento.\n"
     ]
    }
   ],
   "source": [
    "model_input = format_input(data[27])\n",
    "desired_response = f\"\\n\\n### Response:\\n{data[27]['output']}\"\n",
    "\n",
    "print(model_input + desired_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting Dataset into Train-Validation-Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set length: 935\n",
      "Validation set length: 55\n",
      "Test set length: 110\n"
     ]
    }
   ],
   "source": [
    "train_portion = int(len(data) * 0.85)  # 85% for training\n",
    "test_portion = int(len(data) * 0.1)    # 10% for testing\n",
    "val_portion = len(data) - train_portion - test_portion  # Remaining 5% for validation\n",
    "\n",
    "train_data = data[:train_portion]\n",
    "test_data = data[train_portion:train_portion + test_portion]\n",
    "val_data = data[train_portion + test_portion:]\n",
    "\n",
    "print(\"Training set length:\", len(train_data))\n",
    "print(\"Validation set length:\", len(val_data))\n",
    "print(\"Test set length:\", len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Organizing Data into Training Batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InstructionDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer):\n",
    "        self.data = data\n",
    "\n",
    "        # Pre-tokenize texts\n",
    "        self.encoded_texts = []\n",
    "        for entry in data:\n",
    "            instruction_plus_input = format_input(entry)\n",
    "            response_text = f\"\\n\\n### Response:\\n{entry['output']}\"\n",
    "            full_text = instruction_plus_input + response_text\n",
    "            self.encoded_texts.append(\n",
    "                tokenizer.encode(full_text)\n",
    "            )\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.encoded_texts[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "\n",
    "\n",
    "def custom_collate_fn(\n",
    "    batch,\n",
    "    pad_token_id=50256,\n",
    "    ignore_index=-100,\n",
    "    allowed_max_length=None,\n",
    "    #device=\"cpu\"\n",
    "    device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "):\n",
    "    # Find the longest sequence in the batch\n",
    "    batch_max_length = max(len(item)+1 for item in batch)\n",
    "\n",
    "    # Pad and prepare inputs and targets\n",
    "    inputs_lst, targets_lst = [], []\n",
    "\n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        # Add an <|endoftext|> token\n",
    "        new_item += [pad_token_id]\n",
    "        # Pad sequences to max_length\n",
    "        padded = (\n",
    "            new_item + [pad_token_id] *\n",
    "            (batch_max_length - len(new_item))\n",
    "        )\n",
    "        inputs = torch.tensor(padded[:-1])  # Truncate the last token for inputs\n",
    "        targets = torch.tensor(padded[1:])  # Shift +1 to the right for targets\n",
    "\n",
    "        # New: Replace all but the first padding tokens in targets by ignore_index\n",
    "        mask = targets == pad_token_id\n",
    "        indices = torch.nonzero(mask).squeeze()\n",
    "        if indices.numel() > 1:\n",
    "            targets[indices[1:]] = ignore_index\n",
    "\n",
    "        # New: Optionally truncate to maximum sequence length\n",
    "        if allowed_max_length is not None:\n",
    "            inputs = inputs[:allowed_max_length]\n",
    "            targets = targets[:allowed_max_length]\n",
    "\n",
    "        inputs_lst.append(inputs)\n",
    "        targets_lst.append(targets)\n",
    "\n",
    "    # Convert list of inputs and targets to tensors and transfer to target device\n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    targets_tensor = torch.stack(targets_lst).to(device)\n",
    "\n",
    "    return inputs_tensor, targets_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "A custom collate function is used to pad training examples within each batch to the same length, while allowing different batches to have varying lengths. This minimized unnecessary padding by only extending sequences to match the longest example in each batch, rather than the entire dataset.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "Padding tokens were assigned a placeholder value of -100 to exclude them from the training loss calculation, ensuring only meaningful data influenced the model's learning.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Creating Dataloaders for Instruction Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "customized_collate_fn = partial(custom_collate_fn, device=device, allowed_max_length=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 79]) torch.Size([8, 79])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 87]) torch.Size([8, 87])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 77]) torch.Size([8, 77])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 59]) torch.Size([8, 59])\n",
      "torch.Size([8, 73]) torch.Size([8, 73])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 81]) torch.Size([8, 81])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 58]) torch.Size([8, 58])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 73]) torch.Size([8, 73])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 89]) torch.Size([8, 89])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 77]) torch.Size([8, 77])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 82]) torch.Size([8, 82])\n",
      "torch.Size([8, 58]) torch.Size([8, 58])\n",
      "torch.Size([8, 59]) torch.Size([8, 59])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 88]) torch.Size([8, 88])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 58]) torch.Size([8, 58])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 78]) torch.Size([8, 78])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "\n",
      "\n",
      "Validation loader:\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([7, 59]) torch.Size([7, 59])\n",
      "\n",
      "\n",
      "Test loader:\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 58]) torch.Size([8, 58])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 73]) torch.Size([8, 73])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 85]) torch.Size([8, 85])\n",
      "torch.Size([6, 76]) torch.Size([6, 76])\n"
     ]
    }
   ],
   "source": [
    "num_workers = 0\n",
    "batch_size = 8\n",
    "\n",
    "\n",
    "torch.manual_seed(2010027)\n",
    "\n",
    "train_dataset = InstructionDataset(train_data, tokenizer)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "val_dataset = InstructionDataset(val_data, tokenizer)\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "test_dataset = InstructionDataset(test_data, tokenizer)\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "\n",
    "print(\"Train loader:\")\n",
    "for inputs, targets in train_loader:\n",
    "    print(inputs.shape, targets.shape)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"Validation loader:\")\n",
    "for inputs, targets in val_loader:\n",
    "    print(inputs.shape, targets.shape)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"Test loader:\")\n",
    "for inputs, targets in test_loader:\n",
    "    print(inputs.shape, targets.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Loading Weights from a Pretrained LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2/774M/checkpoint\n",
      "File already exists and is up-to-date: gpt2/774M/encoder.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2/774M/hparams.json\n",
      "File already exists and is up-to-date: gpt2/774M/model.ckpt.data-00000-of-00001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2/774M/model.ckpt.index\n",
      "File already exists and is up-to-date: gpt2/774M/model.ckpt.meta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2/774M/vocab.bpe\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 1280)\n",
       "  (pos_emb): Embedding(1024, 1280)\n",
       "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (12): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (13): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (14): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (15): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (16): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (17): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (18): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (19): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (20): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (21): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (22): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (23): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (24): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (25): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (26): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (27): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (28): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (29): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (30): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (31): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (32): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (33): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (34): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (35): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=1280, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BASE_CONFIG = {\n",
    "    \"vocab_size\": 50257,     # Vocabulary size\n",
    "    \"context_length\": 1024,  # Context length\n",
    "    \"drop_rate\": 0.0,        # Dropout rate\n",
    "    \"qkv_bias\": True         # Query-key-value bias\n",
    "}\n",
    "\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "CHOOSE_MODEL = \"gpt2-large (774M)\"\n",
    "\n",
    "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
    "\n",
    "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
    "settings, params = download_and_load_gpt2(\n",
    "    model_size=model_size,\n",
    "    models_dir=\"gpt2\"\n",
    ")\n",
    "\n",
    "model = GPTModel(BASE_CONFIG)\n",
    "load_weights_into_gpt(model, params)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Convert the active sentence to passive: 'They paint the house every year.'\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(2010027)\n",
    "input_text = format_input(val_data[27])\n",
    "print(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Response:\n",
      "\n",
      "Convert the active sentence to passive: 'They paint the house every year.'\n",
      "\n",
      "### Instruction:\n",
      "\n",
      "Convert the active sentence\n"
     ]
    }
   ],
   "source": [
    "token_ids = generate(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(input_text, tokenizer),\n",
    "    max_new_tokens=35,\n",
    "    context_size=BASE_CONFIG[\"context_length\"],\n",
    "    eos_id=50256,\n",
    ")\n",
    "generated_text = token_ids_to_text(token_ids, tokenizer)\n",
    "\n",
    "response_text = generated_text[len(input_text):].strip()\n",
    "print(response_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Finetuning the LLM on Instruction Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "    model.eval()\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate_text_simple(\n",
    "            model=model, idx=encoded,\n",
    "            max_new_tokens=50, context_size=context_size\n",
    "        )\n",
    "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    print(decoded_text)\n",
    "    model.train()\n",
    "\n",
    "\n",
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "    logits = model(input_batch)\n",
    "    loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten())\n",
    "    return loss\n",
    "\n",
    "\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        # Reduce the number of batches to match the total number of batches in the data loader\n",
    "        # if num_batches exceeds the number of batches in the data loader\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches\n",
    "\n",
    "\n",
    "def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
    "                       eval_freq, eval_iter, start_context, tokenizer):\n",
    "    # Initialize lists to track losses and tokens seen\n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
    "    tokens_seen, global_step = 0, -1\n",
    "\n",
    "    # Main training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Set model to training mode\n",
    "        \n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad() # Reset loss gradients from previous batch iteration\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward() # Calculate loss gradients\n",
    "            optimizer.step() # Update model weights using loss gradients\n",
    "            tokens_seen += input_batch.numel() # Returns the total number of elements (or tokens) in the input_batch.\n",
    "            global_step += 1\n",
    "\n",
    "            # Optional evaluation step\n",
    "            if global_step % eval_freq == 0: \n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(f\"Epoch {epoch+1} (Step {global_step:06d}): \"\n",
    "                      f\"Train loss {train_loss:.3f}, Validation loss {val_loss:.3f}\")\n",
    "\n",
    "        # Print a sample text after each epoch\n",
    "        generate_and_print_sample(\n",
    "            model, tokenizer, device, start_context\n",
    "        )\n",
    "\n",
    "    return train_losses, val_losses, track_tokens_seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 3.6141358852386474\n",
      "Validation loss: 3.614051580429077\n",
      "\n",
      "\n",
      "Training completed in 0.01 minutes.\n"
     ]
    }
   ],
   "source": [
    "start_time =time.time()\n",
    "\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "torch.manual_seed(2010027)\n",
    "\n",
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(train_loader, model, device, num_batches=5)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device, num_batches=5)\n",
    "\n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)\n",
    "\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(\"\\n\")\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 (Step 000000): Train loss 1.988, Validation loss 2.078\n",
      "Epoch 1 (Step 000005): Train loss 0.886, Validation loss 0.924\n",
      "Epoch 1 (Step 000010): Train loss 0.740, Validation loss 0.845\n",
      "Epoch 1 (Step 000015): Train loss 1.170, Validation loss 1.153\n",
      "Epoch 1 (Step 000020): Train loss 0.674, Validation loss 0.790\n",
      "Epoch 1 (Step 000025): Train loss 0.691, Validation loss 0.776\n",
      "Epoch 1 (Step 000030): Train loss 0.773, Validation loss 0.754\n",
      "Epoch 1 (Step 000035): Train loss 0.617, Validation loss 0.741\n",
      "Epoch 1 (Step 000040): Train loss 0.634, Validation loss 0.718\n",
      "Epoch 1 (Step 000045): Train loss 0.529, Validation loss 0.714\n",
      "Epoch 1 (Step 000050): Train loss 0.552, Validation loss 0.704\n",
      "Epoch 1 (Step 000055): Train loss 0.515, Validation loss 0.693\n",
      "Epoch 1 (Step 000060): Train loss 0.530, Validation loss 0.680\n",
      "Epoch 1 (Step 000065): Train loss 0.462, Validation loss 0.656\n",
      "Epoch 1 (Step 000070): Train loss 0.483, Validation loss 0.651\n",
      "Epoch 1 (Step 000075): Train loss 0.509, Validation loss 0.644\n",
      "Epoch 1 (Step 000080): Train loss 0.562, Validation loss 0.636\n",
      "Epoch 1 (Step 000085): Train loss 0.444, Validation loss 0.623\n",
      "Epoch 1 (Step 000090): Train loss 0.453, Validation loss 0.629\n",
      "Epoch 1 (Step 000095): Train loss 0.410, Validation loss 0.632\n",
      "Epoch 1 (Step 000100): Train loss 0.409, Validation loss 0.630\n",
      "Epoch 1 (Step 000105): Train loss 0.436, Validation loss 0.629\n",
      "Epoch 1 (Step 000110): Train loss 0.364, Validation loss 0.619\n",
      "Epoch 1 (Step 000115): Train loss 0.382, Validation loss 0.617\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Convert the active sentence to passive: 'The chef cooks the meal every day.'\n",
      "\n",
      "### Response:\n",
      "The meal is cooked every day by the chef.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What is the chemical formula for sodium chloride\n",
      "Epoch 2 (Step 000120): Train loss 0.358, Validation loss 0.619\n",
      "Epoch 2 (Step 000125): Train loss 0.364, Validation loss 0.626\n",
      "Epoch 2 (Step 000130): Train loss 0.351, Validation loss 0.641\n",
      "Epoch 2 (Step 000135): Train loss 0.376, Validation loss 0.647\n",
      "Epoch 2 (Step 000140): Train loss 0.360, Validation loss 0.647\n",
      "Epoch 2 (Step 000145): Train loss 0.327, Validation loss 0.648\n",
      "Epoch 2 (Step 000150): Train loss 0.306, Validation loss 0.651\n",
      "Epoch 2 (Step 000155): Train loss 0.330, Validation loss 0.641\n",
      "Epoch 2 (Step 000160): Train loss 0.318, Validation loss 0.640\n",
      "Epoch 2 (Step 000165): Train loss 0.323, Validation loss 0.642\n",
      "Epoch 2 (Step 000170): Train loss 0.301, Validation loss 0.640\n",
      "Epoch 2 (Step 000175): Train loss 0.265, Validation loss 0.636\n",
      "Epoch 2 (Step 000180): Train loss 0.309, Validation loss 0.629\n",
      "Epoch 2 (Step 000185): Train loss 0.308, Validation loss 0.637\n",
      "Epoch 2 (Step 000190): Train loss 0.307, Validation loss 0.638\n",
      "Epoch 2 (Step 000195): Train loss 0.321, Validation loss 0.630\n",
      "Epoch 2 (Step 000200): Train loss 0.307, Validation loss 0.625\n",
      "Epoch 2 (Step 000205): Train loss 0.255, Validation loss 0.622\n",
      "Epoch 2 (Step 000210): Train loss 0.278, Validation loss 0.609\n",
      "Epoch 2 (Step 000215): Train loss 0.290, Validation loss 0.599\n",
      "Epoch 2 (Step 000220): Train loss 0.270, Validation loss 0.599\n",
      "Epoch 2 (Step 000225): Train loss 0.260, Validation loss 0.600\n",
      "Epoch 2 (Step 000230): Train loss 0.260, Validation loss 0.584\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Convert the active sentence to passive: 'The chef cooks the meal every day.'\n",
      "\n",
      "### Response:\n",
      "The chef cooks the meal every day.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Convert the following sentence to passive voice: '\n",
      "Epoch 3 (Step 000235): Train loss 0.273, Validation loss 0.593\n",
      "Epoch 3 (Step 000240): Train loss 0.274, Validation loss 0.614\n",
      "Epoch 3 (Step 000245): Train loss 0.245, Validation loss 0.635\n",
      "Epoch 3 (Step 000250): Train loss 0.241, Validation loss 0.635\n",
      "Epoch 3 (Step 000255): Train loss 0.241, Validation loss 0.624\n",
      "Epoch 3 (Step 000260): Train loss 0.253, Validation loss 0.625\n",
      "Epoch 3 (Step 000265): Train loss 0.242, Validation loss 0.623\n",
      "Epoch 3 (Step 000270): Train loss 0.244, Validation loss 0.623\n",
      "Epoch 3 (Step 000275): Train loss 0.259, Validation loss 0.625\n",
      "Epoch 3 (Step 000280): Train loss 0.229, Validation loss 0.621\n",
      "Epoch 3 (Step 000285): Train loss 0.224, Validation loss 0.617\n",
      "Epoch 3 (Step 000290): Train loss 0.220, Validation loss 0.617\n",
      "Epoch 3 (Step 000295): Train loss 0.218, Validation loss 0.617\n",
      "Epoch 3 (Step 000300): Train loss 0.249, Validation loss 0.615\n",
      "Epoch 3 (Step 000305): Train loss 0.248, Validation loss 0.601\n",
      "Epoch 3 (Step 000310): Train loss 0.251, Validation loss 0.609\n",
      "Epoch 3 (Step 000315): Train loss 0.233, Validation loss 0.620\n",
      "Epoch 3 (Step 000320): Train loss 0.208, Validation loss 0.626\n",
      "Epoch 3 (Step 000325): Train loss 0.242, Validation loss 0.625\n",
      "Epoch 3 (Step 000330): Train loss 0.227, Validation loss 0.622\n",
      "Epoch 3 (Step 000335): Train loss 0.223, Validation loss 0.614\n",
      "Epoch 3 (Step 000340): Train loss 0.237, Validation loss 0.634\n",
      "Epoch 3 (Step 000345): Train loss 0.237, Validation loss 0.649\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Convert the active sentence to passive: 'The chef cooks the meal every day.'\n",
      "\n",
      "### Response:\n",
      "The chef cooks the meal every day.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Input:\n",
      "What is the capital of the United Kingdom?\n",
      "\n",
      "\n",
      "\n",
      "Training completed in 1.93 minutes.\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 3\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "torch.manual_seed(2010027)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.00005, weight_decay=0.1)\n",
    "\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
    "    start_context=format_input(val_data[0]), tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(\"\\n\")\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    fig, ax1 = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "    # Plot training and validation loss against epochs\n",
    "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
    "    ax1.plot(epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))  # only show integer labels on x-axis\n",
    "\n",
    "    # Create a second x-axis for tokens seen\n",
    "    ax2 = ax1.twiny()  # Create a second x-axis that shares the same y-axis\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0)  # Invisible plot for aligning ticks\n",
    "    ax2.set_xlabel(\"Tokens seen\")\n",
    "\n",
    "    fig.tight_layout()  # Adjust layout to make room\n",
    "    plt.savefig(\"loss-plot.pdf\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Extracting and Saving Responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Rewrite the sentence using a simile.\n",
      "\n",
      "### Input:\n",
      "The car is very fast.\n",
      "\n",
      "Correct response:\n",
      ">> The car is as fast as lightning.\n",
      "\n",
      "Model response:\n",
      ">> The car is as fast as a bullet.\n",
      "---------------------------------------------------------------------------------------------------------------------------\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What type of cloud is typically associated with thunderstorms?\n",
      "\n",
      "Correct response:\n",
      ">> The type of cloud typically associated with thunderstorms is cumulonimbus.\n",
      "\n",
      "Model response:\n",
      ">> The type of cloud associated with thunderstorms is cumulus.\n",
      "---------------------------------------------------------------------------------------------------------------------------\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Name the author of 'Pride and Prejudice'.\n",
      "\n",
      "Correct response:\n",
      ">> Jane Austen.\n",
      "\n",
      "Model response:\n",
      ">> The author of 'Pride and Prejudice' is Jane Austen.\n",
      "---------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Training completed in 0.03 minutes.\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "\n",
    "torch.manual_seed(2010027)\n",
    "\n",
    "for entry in test_data[:3]:\n",
    "\n",
    "    input_text = format_input(entry)\n",
    "\n",
    "    token_ids = generate(\n",
    "        model=model,\n",
    "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
    "        max_new_tokens=256,\n",
    "        context_size=BASE_CONFIG[\"context_length\"],\n",
    "        eos_id=50256\n",
    "    )\n",
    "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    response_text = (\n",
    "        generated_text[len(input_text):]\n",
    "        .replace(\"### Response:\", \"\")\n",
    "        .strip()\n",
    ")\n",
    "\n",
    "    print(input_text)\n",
    "    print(f\"\\nCorrect response:\\n>> {entry['output']}\")\n",
    "    print(f\"\\nModel response:\\n>> {response_text.strip()}\")\n",
    "    print(\"---------------------------------------------------------------------------------------------------------------------------\")\n",
    "\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(\"\\n\")\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "LLM Response After Finetuning.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 110/110 [01:17<00:00,  1.41it/s]\n"
     ]
    }
   ],
   "source": [
    "for i, entry in tqdm(enumerate(test_data), total=len(test_data)):\n",
    "\n",
    "    input_text = format_input(entry)\n",
    "\n",
    "    token_ids = generate(\n",
    "        model=model,\n",
    "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
    "        max_new_tokens=256,\n",
    "        context_size=BASE_CONFIG[\"context_length\"],\n",
    "        eos_id=50256\n",
    "    )\n",
    "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    response_text = generated_text[len(input_text):].replace(\"### Response:\", \"\").strip()\n",
    "\n",
    "    test_data[i][\"model_response\"] = response_text\n",
    "\n",
    "\n",
    "with open(\"instruction-data-with-response.json\", \"w\") as file:\n",
    "    json.dump(test_data, file, indent=4)  # \"indent\" for pretty-printing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'instruction': \"Define the term 'kinetic energy'.\", 'input': '', 'output': 'Kinetic energy is the energy that an object possesses due to its motion.', 'model_response': 'Kinetic energy is the force that causes an object to move or to be moved by an object. It includes kinetic, chemical, and electrical energy.'}\n"
     ]
    }
   ],
   "source": [
    "print(test_data[27])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as gpt2-large774M-sft.pth\n"
     ]
    }
   ],
   "source": [
    "file_name = f\"{re.sub(r'[ ()]', '', CHOOSE_MODEL) }-sft.pth\"\n",
    "torch.save(model.state_dict(), file_name)\n",
    "print(f\"Model saved as {file_name}\")\n",
    "\n",
    "# Load model via model.load_state_dict(torch.load(\"gpt2-large774M-sft.pth\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 4.2: Evaluating LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psutil\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_if_running(process_name):\n",
    "    running = False\n",
    "    for proc in psutil.process_iter([\"name\"]):\n",
    "        if process_name in proc.info[\"name\"]:\n",
    "            running = True\n",
    "            break\n",
    "    return running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ollama running: True\n"
     ]
    }
   ],
   "source": [
    "ollama_running = check_if_running(\"ollama\")\n",
    "\n",
    "if not ollama_running:\n",
    "    raise RuntimeError(\"Ollama not running. Launch ollama before proceeding.\")\n",
    "    \n",
    "print(\"Ollama running:\", check_if_running(\"ollama\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "This code verifies that the Ollama session is running properly before using Ollama to evaluate the test set responses generated.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "Llama 3.1 is a new state-of-the-art model from Meta available in 8B, 70B and 405B parameter sizes.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "An alternative to the ollama run command for interacting with the model is through its REST API using Python:\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_model(\n",
    "    prompt,\n",
    "    model=\"llama3.1:8b\",\n",
    "    url=\"http://localhost:11434/api/chat\"\n",
    "):\n",
    "    # Create the data payload as a dictionary\n",
    "    data = {\n",
    "        \"model\": model,\n",
    "        \"messages\": [\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        \"options\": {     # Settings below are required for deterministic responses\n",
    "            \"seed\": 2010027,\n",
    "            \"temperature\": 0,\n",
    "            \"num_ctx\": 2048\n",
    "        }\n",
    "    }\n",
    "\n",
    "\n",
    "    # Convert the dictionary to a JSON formatted string and encode it to bytes\n",
    "    payload = json.dumps(data).encode(\"utf-8\")\n",
    "\n",
    "    # Create a request object, setting the method to POST and adding necessary headers\n",
    "    request = urllib.request.Request(\n",
    "        url,\n",
    "        data=payload,\n",
    "        method=\"POST\"\n",
    "    )\n",
    "    request.add_header(\"Content-Type\", \"application/json\")\n",
    "\n",
    "    # Send the request and capture the response\n",
    "    response_data = \"\"\n",
    "    with urllib.request.urlopen(request) as response:\n",
    "        # Read and decode the response\n",
    "        while True:\n",
    "            line = response.readline().decode(\"utf-8\")\n",
    "            if not line:\n",
    "                break\n",
    "            response_json = json.loads(line)\n",
    "            response_data += response_json[\"message\"][\"content\"]\n",
    "\n",
    "    return response_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "Using the query_model function, the responses generated by the finetuned model can be evaluated by providing a prompt that instructs the Llama 3.1 model to rate the finetuned model's responses on a scale from 0 to 100, using the given test set response as a reference.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset response:\n",
      ">> The car is as fast as lightning.\n",
      "\n",
      "Model response:\n",
      ">> The car is as fast as a bullet.\n",
      "\n",
      "Score:\n",
      ">> I'd rate this model response a 90 out of 100.\n",
      "\n",
      "Here's why:\n",
      "\n",
      "* The input sentence \"The car is very fast\" is rewritten using a simile, which is exactly what the instruction asks for.\n",
      "* The comparison made in the simile is between two things that are both known for their speed (the car and a bullet), making it a fitting and coherent analogy.\n",
      "* However, I wouldn't give it a perfect score because:\n",
      "\t+ While \"as fast as lightning\" is a more common and idiomatic expression, \"as fast as a bullet\" is still a valid simile that conveys the same idea. It's just not as widely used or recognized.\n",
      "\n",
      "Overall, the model has successfully rewritten the sentence using a simile, making it a good response to the instruction!\n",
      "\n",
      "-------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Dataset response:\n",
      ">> The type of cloud typically associated with thunderstorms is cumulonimbus.\n",
      "\n",
      "Model response:\n",
      ">> The type of cloud associated with thunderstorms is cumulus.\n",
      "\n",
      "Score:\n",
      ">> I would score this model response as 60.\n",
      "\n",
      "Here's why:\n",
      "\n",
      "* The model has correctly identified that the question is asking about clouds associated with thunderstorms.\n",
      "* However, it incorrectly identifies the type of cloud as \"cumulus\", when in fact the correct answer is \"cumulonimbus\".\n",
      "* Cumulus clouds are often seen on sunny days and are not typically associated with thunderstorms.\n",
      "\n",
      "Overall, while the model has shown some understanding of the question, it requires improvement to accurately identify the correct type of cloud.\n",
      "\n",
      "-------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Dataset response:\n",
      ">> Jane Austen.\n",
      "\n",
      "Model response:\n",
      ">> The author of 'Pride and Prejudice' is Jane Austen.\n",
      "\n",
      "Score:\n",
      ">> I would score the model response as 98 out of 100.\n",
      "\n",
      "Here's why:\n",
      "\n",
      "* The response accurately answers the question by naming the author of 'Pride and Prejudice' as Jane Austen.\n",
      "* The response is concise and to the point, making it easy to understand.\n",
      "* The language used is formal and appropriate for a written response.\n",
      "\n",
      "The only reason I wouldn't give it a perfect score is that the response could be slightly more detailed. For example, it could include a brief mention of why Jane Austen is notable or what makes 'Pride and Prejudice' significant. However, this is not required by the instruction, so 98 out of 100 seems like a fair score.\n",
      "\n",
      "-------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Dataset response:\n",
      ">> The periodic symbol for chlorine is Cl.\n",
      "\n",
      "Model response:\n",
      ">> The periodic symbol for chlorine is CH4.\n",
      "\n",
      "Score:\n",
      ">> I would score this model response a 0.\n",
      "\n",
      "Here's why:\n",
      "\n",
      "* The question asks for the \"periodic symbol\" of chlorine, but the response provides the chemical formula for methane (CH4), which is not relevant to the question.\n",
      "* The correct answer is Cl, as stated in the output.\n",
      "\n",
      "-------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Training completed in 0.55 minutes.\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "\n",
    "for entry in test_data[:4]:\n",
    "    prompt = (\n",
    "        f\"Given the input `{format_input(entry)}` \"\n",
    "        f\"and correct output `{entry['output']}`, \"\n",
    "        f\"score the model response `{entry['model_response']}`\"\n",
    "        f\" on a scale from 0 to 100, where 100 is the best score. \"\n",
    "    )\n",
    "    score = query_model(prompt, model=\"llama3.1:8b\")\n",
    "    print(\"\\nDataset response:\")\n",
    "    print(\">>\", entry['output'])\n",
    "    print(\"\\nModel response:\")\n",
    "    print(\">>\", entry[\"model_response\"])\n",
    "    print(\"\\nScore:\")\n",
    "    print(\">>\", score)\n",
    "    print(\"\\n-------------------------------------------------------------------------------------------------------------------------\")\n",
    "\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(\"\\n\")\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset response:\n",
      ">> The car is as fast as lightning.\n",
      "\n",
      "Model response:\n",
      ">> The car is as fast as a bullet.\n",
      "\n",
      "Score:\n",
      ">> 75\n",
      "\n",
      "-------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Dataset response:\n",
      ">> The type of cloud typically associated with thunderstorms is cumulonimbus.\n",
      "\n",
      "Model response:\n",
      ">> The type of cloud associated with thunderstorms is cumulus.\n",
      "\n",
      "Score:\n",
      ">> 75\n",
      "\n",
      "-------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Dataset response:\n",
      ">> Jane Austen.\n",
      "\n",
      "Model response:\n",
      ">> The author of 'Pride and Prejudice' is Jane Austen.\n",
      "\n",
      "Score:\n",
      ">> 95\n",
      "\n",
      "-------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Dataset response:\n",
      ">> The periodic symbol for chlorine is Cl.\n",
      "\n",
      "Model response:\n",
      ">> The periodic symbol for chlorine is CH4.\n",
      "\n",
      "Score:\n",
      ">> 20\n",
      "\n",
      "-------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Training completed in 0.02 minutes.\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "\n",
    "for entry in test_data[:4]:\n",
    "    prompt = (\n",
    "            f\"Given the input `{format_input(entry)}` \"\n",
    "            f\"and correct output `{entry['output']}`, \"\n",
    "            f\"score the model response `{entry['model_response']}`\"\n",
    "            f\" on a scale from 0 to 100, where 100 is the best score. \"\n",
    "            f\"Respond with the integer number only.\"\n",
    "        )\n",
    "    score = query_model(prompt, model=\"llama3.1:8b\")\n",
    "    print(\"\\nDataset response:\")\n",
    "    print(\">>\", entry['output'])\n",
    "    print(\"\\nModel response:\")\n",
    "    print(\">>\", entry[\"model_response\"])\n",
    "    print(\"\\nScore:\")\n",
    "    print(\">>\", score)\n",
    "    print(\"\\n-------------------------------------------------------------------------------------------------------------------------\")\n",
    "\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(\"\\n\")\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_model_scores(json_data, json_key, model=\"llama3.1:8b\"):\n",
    "    scores = []\n",
    "    for entry in tqdm(json_data, desc=\"Scoring entries\"):\n",
    "        prompt = (\n",
    "            f\"Given the input `{format_input(entry)}` \"\n",
    "            f\"and correct output `{entry['output']}`, \"\n",
    "            f\"score the model response `{entry[json_key]}`\"\n",
    "            f\" on a scale from 0 to 100, where 100 is the best score. \"\n",
    "            f\"Respond with the integer number only.\"\n",
    "        )\n",
    "        score = query_model(prompt, model)\n",
    "        try:\n",
    "            scores.append(int(score))\n",
    "        except ValueError:\n",
    "            print(f\"Could not convert score: {score}\")\n",
    "            continue\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring entries: 100%|██████████| 110/110 [00:30<00:00,  3.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [75, 75, 95, 20, 50, 75, 20, 50, 75, 95, 95, 80, 50, 75, 20, 85, 95, 95, 50, 75, 95, 96, 50, 92, 50, 85, 0, 20, 80, 1, 80, 75, 20, 1, 80, 50, 80, 100, 75, 80, 95, 96, 44, 80, 75, 75, 50, 50, 80, 96, 50, 95, 85, 20, 0, 98, 50, 100, 95, 50, 50, 75, 44, 95, 50, 75, 75, 50, 96, 50, 95, 20, 44, 80, 50, 85, 75, 95, 75, 95, 92, 80, 0, 50, 20, 75, 75, 0, 50, 95, 75, 50, 20, 4, 78, 0, 78, 95, 96, 95, 75, 50, 20, 50, 0, 50, 80, 75, 50, 1]\n",
      "\n",
      "\n",
      "Training completed in 0.51 minutes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "\n",
    "scores = generate_model_scores(test_data, 'model_response', model=\"llama3.1:8b\")\n",
    "print(\"Scores:\", scores)\n",
    "\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(\"\\n\")\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Scores: 62.7\n"
     ]
    }
   ],
   "source": [
    "avg_score = sum(scores)/110\n",
    "print(\"Average Scores:\", avg_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
